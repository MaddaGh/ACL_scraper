@inproceedings{10.1145/3706599.3719747,
author = {Pang, Rock Yuren and Maheshwari, Rohit and Yu, Julie and Reinecke, Katharina},
title = {Synthetic Conversation: How Computing Researchers Engage Multi-Perspective Dialogues to Brainstorm Societal Impacts},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3719747},
doi = {10.1145/3706599.3719747},
abstract = {There have been increasing calls for computing researchers to consider the negative societal impacts of their work. However, anticipating these impacts remains challenging, as computing researchers often do not have access to diverse perspectives. Here, we explore how computing researchers brainstorm the negative societal impacts of computing innovations using a multi-agent dialog prototype called Weaver as a probe that represents synthetic stakeholder conversations. Through think-aloud sessions and interviews with 12 participants, we evaluate how computing researchers perceive and engage with such a system, and whether they find it beneficial compared to using no such system or using ChatGPT. Our findings revealed that participants valued the conversations with the multi-agent system and considered societal impacts from new angles. Participants reported gaining insights and agency to reflect on issues rather than passively consuming pre-generated content. We discuss the findings, implications, and next steps for using a multi-agent system to brainstorm about the societal impacts of computing technologies.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {497},
numpages = {7},
keywords = {Multi-agent systems, Brainstorming, Human-AI Interaction, LLM},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3544549.3585588,
author = {Liu, Yimeng and Ritchie, Jacob and Kratz, Sven and Sra, Misha and Smith, Brian A. and Monroy-Hern\'{a}ndez, Andr\'{e}s and Vaish, Rajan},
title = {Memento Player: Shared Multi-Perspective Playback of Volumetrically-Captured Moments in Augmented Reality},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585588},
doi = {10.1145/3544549.3585588},
abstract = {Capturing and reliving memories allow us to record, understand and share our past experiences. Currently, the most common approach to revisiting past moments is viewing photos and videos. These 2D media capture past events that reflect a recorder’s first-person perspective. The development of technology for accurately capturing 3D content presents an opportunity for new types of memory reliving, allowing greater immersion without perspective limitations. In this work, we adopt 2D and 3D moment-recording techniques and build a moment-reliving experience in AR that combines both display methods. Specifically, we use AR glasses to record 2D point-of-view (POV) videos, and volumetric capture to reconstruct 3D moments in AR. We allow seamless switching between AR and POV videos to enable immersive moment reliving and viewing of high-resolution details. Users can also navigate to a specific point in time using playback controls. Control is synchronized between multiple users for shared viewing.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {205},
numpages = {9},
keywords = {augmented reality, moment reliving, multi-perspective, shared and social experience, volumetric capture},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3706598.3713524,
author = {Meyer, Anna P. and Kim, Yea-Seul and D'Antoni, Loris and Albarghouthi, Aws},
title = {Perceptions of the Fairness Impacts of Multiplicity in Machine Learning},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713524},
doi = {10.1145/3706598.3713524},
abstract = {Machine learning (ML) is increasingly used in high-stakes settings, yet multiplicity – the existence of multiple good models – means that some predictions are essentially arbitrary. ML researchers and philosophers posit that multiplicity poses a fairness risk, but no studies have investigated whether stakeholders agree. In this work, we conduct a survey to see how multiplicity impacts lay stakeholders’ – i.e., decision subjects’ – perceptions of ML fairness, and which approaches to address multiplicity they prefer. We investigate how these perceptions are modulated by task characteristics (e.g., stakes and uncertainty). Survey respondents think that multiplicity threatens the fairness of model outcomes, but not the appropriateness of using the model, even though existing work suggests the opposite. Participants are strongly against resolving multiplicity by using a single model (effectively ignoring multiplicity) or by randomizing the outcomes. Our results indicate that model developers should be intentional about dealing with multiplicity in order to maintain fairness.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {524},
numpages = {15},
keywords = {Fairness, Fairness Perceptions, Fairness in Machine Learning, Multiplicity, Stakeholder Survey},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3411763.3450364,
author = {Howell, Noura and F. Schulte, Britta and Twigger Holroyd, Amy and Fat\'{a}s Arana, Roc\'{\i}o and Sharma, Sumita and Eden, Grace},
title = {Calling for a Plurality of Perspectives on Design Futuring: An Un-Manifesto},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450364},
doi = {10.1145/3411763.3450364},
abstract = {The Futures Cone, a prominent model in design futuring, is useful for promoting discussions about possible, plausible, probable, and preferable futures. Yet this model has limitations, such as representing diverse human experiences as a singular point of “the present” and implicitly embedding notions of linear progress. Responding to this, we argue that a plurality of perspectives is needed to engage imaginations that depict a diverse unfolding of potential futures. Through reflecting on our own cultural and professional backgrounds, we offer five perspectives for design futuring as a contribution to this plurality: Parallel Presents, “I Am Time”, Epithelial Metaphors, the Uncertainties Cone, and Meet (with) “Speculation”. These perspectives open alternative approaches to design futuring, move outside prevalent notions of technological progress, and foreground interdependent, relational agencies.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {31},
numpages = {10},
keywords = {design futuring, discursive design, plurality, speculative design, un-manifesto},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3290605.3300369,
author = {Rankin, Yolanda A. and Han, Na-eun},
title = {Exploring the Plurality of Black Women's Gameplay Experiences},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300369},
doi = {10.1145/3290605.3300369},
abstract = {Few gender-focused studies of video games explore the gameplay experiences of women of color, and those that do tend to only emphasize negative phenomena (i.e., racial or gender discrimination). In this paper, we conduct an exploratory case study attending to the motivations and gaming practices of Black college women. Questionnaire responses and focus group discussion illuminate the plurality of gameplay experiences for this specific population of Black college women. Sixty-five percent of this population enjoy the ubiquity of mobile games with casual and puzzle games being the most popular genres. However, academic responsibilities and competing recreational interests inhibit frequent gameplay. Consequently, this population of Black college women represent two types of casual gamers who report positive gameplay experiences, providing insights into creating a more inclusive gaming subculture.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {black women, gaming, gendered game studies, intersectionality},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3491102.3501892,
author = {Diamond, Lindsay Levkoff and Batan, Hande and Anderson, Jennings and Palen, Leysia},
title = {The Polyvocality of Online COVID-19 Vaccine Narratives that Invoke Medical Racism},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501892},
doi = {10.1145/3491102.3501892},
abstract = {Vaccine hesitancy has always been a public health concern, and anti-vaccine campaigns that proliferate disinformation have gained traction across the US in the last 25 years. The demographics of resistance are varied, with health, religious, and, increasingly, political concerns cited as reasons. With the COVID-19 pandemic igniting the fastest development of vaccines to date, mis- and disinformation about them have become inflammatory, with campaigning allegedly including racial targeting. Through a primarily qualitative investigation, this study inductively examines a large online vaccine discussion space that invokes references to the unethical Tuskegee Syphilis Study to understand how tactics of racial targeting of Black Americans might appear publicly. We find that such targeting is entangled with a genuine discussion about medical racism and vaccine hesitancy. Across 12 distinct voices that address race, medical racism, and vaccines, we discuss how mis- and disinformation sit alongside accurate information in a “polyvocal” space.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {145},
numpages = {21},
keywords = {Anti-Vaccine, COVID-19, Disinformation, Medical Racism, Misinformation, Pandemic, Public Health, Social Media, Vaccines},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3706598.3713675,
author = {Ashkinaze, Joshua and Fry, Emily and Edara, Narendra and Gilbert, Eric and Budak, Ceren},
title = {Plurals: A System for Guiding LLMs via Simulated Social Ensembles},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713675},
doi = {10.1145/3706598.3713675},
abstract = {Recent debates raised concerns that language models may favor certain viewpoints. But what if the solution is not to aim for a “view from nowhere” but rather to leverage different viewpoints? We introduce Plurals, a system and Python library for pluralistic AI deliberation. Plurals consists of Agents (LLMs, optionally with personas) which deliberate within customizable Structures, with Moderators overseeing deliberation. Plurals is a generator of simulated social ensembles. Plurals integrates with government datasets to create nationally representative personas, includes deliberation templates inspired by deliberative democracy, and allows users to customize both information-sharing structures and deliberation behavior within Structures. Six case studies demonstrate fidelity to theoretical constructs and efficacy. Three randomized experiments show simulated focus groups produced output resonant with an online sample of the relevant audiences (chosen over zero-shot generation in 75% of trials). Plurals is both a paradigm and a concrete system for pluralistic AI.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {245},
numpages = {21},
keywords = {Human-Computer Interaction, Human-AI Interaction, Artificial Intelligence, Multi-Agent Systems, Pluralism},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/2858036.2858530,
author = {B\o{}dker, Susanne and Klokmose, Clemens Nylandsted},
title = {Dynamics, Multiplicity and Conceptual Blends in HCI},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858530},
doi = {10.1145/2858036.2858530},
abstract = {Discussions on what makes user interfaces "natural" or "intuitive" have led researchers to apply Fauconnier and Turner's theory of Conceptual Blends to explain how users rely on familiar and real-world concepts when they learn to use new digital technologies -- as a blend of experiences from the --physical and the "digital" world. This pursuit has multiple challenges of which we address four: The continuous dynamic development of experiences; the multiplicity and complexity involved; the distinction between "real" and "virtual" experiences, and finally applying descriptive concepts predictively. Based on our background in activity theoretical HCI we discuss two cases to nuance the discussion of conceptual blends and HCI. We provide an understanding of conceptual blends beyond one-to-one static blends, and immediately recognizable concepts. We focus on multiplicity, dynamics and learning, and in that we provide a more advanced methodological scaffolding of analyses of conceptual blends, hence we propose that designers need to seed blends in design.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {2538–2548},
numpages = {11},
keywords = {interaction design, conceptual blends, activity theory},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/3025453.3025606,
author = {Green, David Philip and Bowen, Simon and Hook, Jonathan and Wright, Peter},
title = {Enabling Polyvocality in Interactive Documentaries through "Structural Participation"},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025606},
doi = {10.1145/3025453.3025606},
abstract = {Recent innovations in online, social and interactive media have led to the emergence of new forms of documentary, such as interactive documentaries ('i-Docs'), with qualities that lend themselves to more open and inclusive production structures. Still, little is known about the experience of making and/or participating-in these kinds of documentary. Our two-year in-the-wild study engaged a large community-of-interest in the production of an i-Doc to explore the ethically-desirable yet challenging aim of enabling multiple subjects to have agency and control over their representation in a documentary. Our study reveals insights into the experiences of participating in an i-Doc and highlights key sociotechnical challenges. We argue that new sociotechnical infrastructure is needed, that frames both "executory" and "structural" forms of participation as symbiotic elements of a co-design process.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6317–6329},
numpages = {13},
keywords = {authorship, co-design, documentary, grassroots, i-docs, interactivity, narrative, participation},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/3706598.3713496,
author = {Xu, Shuchang and Jin, Xiaofu and Qu, Huamin and Yan, Yukang},
title = {DanmuA11y: Making Time-Synced On-Screen Video Comments (Danmu) Accessible to Blind and Low Vision Users via Multi-Viewer Audio Discussions},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713496},
doi = {10.1145/3706598.3713496},
abstract = {By overlaying time-synced user comments on videos, Danmu creates a co-watching experience for online viewers. However, its visual-centric design poses significant challenges for blind and low vision (BLV) viewers. Our formative study identified three primary challenges that hinder BLV viewers’ engagement with Danmu: the lack of visual context, the speech interference between comments and videos, and the disorganization of comments. To address these challenges, we present DanmuA11y, a system that makes Danmu accessible by transforming it into multi-viewer audio discussions. DanmuA11y incorporates three core features: (1) Augmenting Danmu with visual context, (2) Seamlessly integrating Danmu into videos, and (3) Presenting Danmu via multi-viewer discussions. Evaluation with twelve BLV viewers demonstrated that DanmuA11y significantly improved Danmu comprehension, provided smooth viewing experiences, and fostered social connections among viewers. We further highlight implications for enhancing commentary accessibility in video-based social media and live-streaming platforms.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {293},
numpages = {22},
keywords = {Visual Impairment, Blind, Low Vision, Video, Social Media, Danmaku, Danmu, Bullet Comment},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3544549.3585885,
author = {Kayukawa, Seita and Higuchi, Keita and Morishima, Shigeo and Sakurada, Ken},
title = {3DMovieMap: an Interactive Route Viewer for Multi-Level Buildings},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3585885},
doi = {10.1145/3544549.3585885},
abstract = {We present an interactive route viewer system, 3DMovieMap, which generates and shows navigation movies walking through multi-level buildings, such as a science museum, airport, and university building. Movie map systems can provide users with visual cues by synthesizing navigation movies based on their inputs of routes. However, existing systems are limited to flat areas such as city areas. We aim to extend Movie Map to generate navigation movies for multi-level buildings. The 3DMovieMap system generates a movie map from an equirectangular movie via a visual Simultaneous Localization and Mapping technology. Users select waypoints on the floor maps. 3DMovieMap calculates the shortest path that visits these points and generates a navigation movie along the route. We created four movie maps of buildings and asked two participants to use our system and provide feedback for further improvements. We will be releasing an open dataset of equirectangular movies captured in a science museum.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {2},
numpages = {11},
keywords = {equirectangular movie dataset, indoor environment, movie map, navigation},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3290605.3300236,
author = {Schofield, Tom and Foster Smith, Daniel and Bozoglu, G\"{o}n\"{u}l and Whitehead, Christopher},
title = {Design and Plural Heritages: Composing Critical Futures},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300236},
doi = {10.1145/3290605.3300236},
abstract = {We make theoretical and methodological contributions to the CHI community by introducing comparisons between contemporary Critical Heritage research and some forms of experimental design practice. Beginning by identifying three key approaches in contemporary heritage research: Critical Heritage, Plural Heritages and Future Heritage we introduce these in turn, while exploring their significance for thinking about design, knowledge and diversity. We discuss our efforts to apply ideas integrating Critical Heritage and design through the adoption of known Research through Design techniques in a research project in Istanbul, Turkey describing the design of our study and how this was productive of sensory and speculative reflection on the past. Finally, we reflect on the usefulness of such methods in developing new interactive technologies in heritage contexts and go on to propose a series of recommendations for a future Critical Heritage Design practice.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {critical heritage, cultural probes, future heritage, plural heritages},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/2468356.2468746,
author = {van Allen, Philip and McVeigh-Schultz, Joshua and Brown, Brooklyn and Kim, Hye Mi and Lara, Daniel},
title = {AniThings: animism and heterogeneous multiplicity},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468746},
doi = {10.1145/2468356.2468746},
abstract = {This paper explores the metaphor of animism as a methodological framework for interaction design and, in particular, advocates for a form of animism the authors term 'heterogeneous multiplicity.' Animism can make valuable contributions within ubiquitous computing contexts, where objects with designed behaviors tend to evoke a perception that they have autonomy, intention, personality and an inner life. Furthermore, animism that supports heterogeneous multiplicity offers unique opportunities to stimulate human creativity through embodied engagement with an ecology of things. To demonstrate the concept of heterogeneous multiplicity, the authors present a speculative design project, AniThings, that intertwines multiple animistic collaborators to position activities of digital resource discovery and curation beyond the narrow domain of recommendation engines and personal feeds. The project illustrates an ecology of six tangible, interactive objects that, respectively, draw from a variety of digital resources and inhabit a range of variously positioned stances towards their human collaborators and each other. This diversity of behaviors, resources, and positionality makes AniThings ideal for supporting open-ended ideation and collaborative imagining activities.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2247–2256},
numpages = {10},
keywords = {animism, creative collaboration, design fiction, ecology of things, heterogeneous multiplicity, speculative design, ubiquitous computing},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/3334480.3382856,
author = {Kim, Jung-Hwa and Jeong, Jin-Woo},
title = {A Preliminary Study on Performance Evaluation of Multi-View Multi-Modal Gaze Estimation under Challenging Conditions},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382856},
doi = {10.1145/3334480.3382856},
abstract = {In this paper, we address gaze estimation under practical and challenging conditions. Multi-view and multi-modal learning have been considered useful for various complex tasks; however, an in-depth analysis or a large-scale dataset on multi-view, multi-modal gaze estimation under a long-distance setup with a low illumination is still very limited. To address these limitations, first, we construct a dataset of images captured under challenging conditions. And we propose a simple deep learning architecture that can handle multi-view multi-modal data for gaze estimation. Finally, we conduct a performance evaluation of the proposed network with the constructed dataset to understand the effects of multiple views of a user and multi-modality (RGB, depth, and infrared). We report various findings from our preliminary experimental results and expect this would be helpful for gaze estimation studies to deal with challenging conditions.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–7},
numpages = {7},
keywords = {deep neural networks, gaze estimation, multi-modal interaction, multi-view learning},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/1124772.1124817,
author = {Nacenta, Miguel A. and Sallam, Samer and Champoux, Bernard and Subramanian, Sriram and Gutwin, Carl},
title = {Perspective cursor: perspective-based interaction for multi-display environments},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124817},
doi = {10.1145/1124772.1124817},
abstract = {Multi-display environments and smart meeting rooms are now becoming more common. These environments build a shared display space from variety of devices: tablets, projected surfaces, tabletops, and traditional monitors. Since the different display surfaces are usually not organized in a single plane, traditional schemes for stitching the displays together can cause problems for interaction. However, there is a more natural way to compose display space -- using perspective. In this paper, we develop interaction techniques for multi-display environments that are based on the user's perspective on the room. We designed the Perspective Cursor, a mapping of cursor to display space that appears natural and logical from wherever the user is located. We conducted an experiment to compare two perspective-based techniques, the Perspective Cursor and a beam-based technique, with traditional stitched displays. We found that both perspective techniques were significantly faster for targeting tasks than the traditional technique, and that Perspective Cursor was the most preferred method. Our results show that integrating perspective into the design of multi-display environments can substantially improve performance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {289–298},
numpages = {10},
keywords = {direct-manipulation interfaces, laser pointing, multi-display interaction techniques, multi-monitor environments},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/3706598.3713725,
author = {Sarma, Abhraneel and Hedayati, Maryam and Kay, Matthew},
title = {More Forecasts, More (Decision) Problems: How Uncertainty Representations for Multiple Forecasts Impact Decision Making},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713725},
doi = {10.1145/3706598.3713725},
abstract = {Users often have access to multiple forecasts regarding an event. Different forecasts incorporate different assumptions and epistemic information. A growing body of work argues against decision-making solely based on expected utility maximisation strategies in multiple forecasts scenarios, in favour of other strategies such as the maximin expected utility. In this work, we compare two different approaches for depicting epistemic uncertainty—ensembles (a direct representation of multiple forecasts) and p-boxes (a representation which only communicates the bounds of epistemic uncertainty)—in plots where individual distributions are represented as cumulative distribution plots (CDFs). We conduct three experiments to investigate the impact of the visual representation on the decision-making strategies that people adopt. Our results suggest that participants adopt conservative decision-making strategies (i.e. place greater weight on the worst-case forecast than the best-case forecast) for both p-boxes and ensembles if the set of forecasts are uniformly distributed. However, if a majority of the forecasts are clustered near one of the bounds, participants may discount the forecast which appears as a visual outlier.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {251},
numpages = {14},
keywords = {multiple forecasts, uncertainty visualization, decision-making},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713410,
author = {Jeong, Jae-Yeop and Jeong, Jin-Woo},
title = {Understanding User Behavior in Window Selection using Dragging for Multiple Targets},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713410},
doi = {10.1145/3706598.3713410},
abstract = {Window selection is a fundamental method in desktop environments for interacting with multiple targets, typically performed by successive operations like click-drag-release (i.e., a single sequence of dragging). Although this method is common in GUI interactions, there has been limited research to understand user behavior during window selection. This study explores user behavior and performance during window selection using dragging. We empirically studied the impact of several GUI parameters — including the size, interval, number, and layout of targets — on window selection for multiple targets. Based on well-established existing motor models, we analyzed user behavior in terms of time performance and derived a more suitable model. Additionally, our new prediction model effectively predicted time performance in partially constrained scenarios. This study provides new insights into user behavior during window selection for multiple targets. We hope that our research findings will assist GUI designers, practitioners, and researchers in testing their designs.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {855},
numpages = {21},
keywords = {Window selection, dragging, graphical user interface, multi-target selection, human motor performance, behavior modeling},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706598.3713629,
author = {Shi, Han and Luo, Hanzhong and Yi, HyeonBeom and Je, Seungwoo},
title = {ReachPad: Interacting with Multiple Virtual Screens using a Single Physical Pad through Haptic Retargeting},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713629},
doi = {10.1145/3706598.3713629},
abstract = {The advancement of Virtual Reality (VR) has expanded 2D user interfaces into 3D space. This change has introduced richer interaction modalities but also brought challenges, especially the lack of haptic feedback in mid-air interactions. Previous research has explored various methods to provide feedback for interface interactions, but most approaches require specialized haptic devices. We introduce haptic retargeting to enable users to control multiple virtual screens in VR using a simple flat pad, which serves as a single physical proxy to support seamless interaction across multiple virtual screens. We conducted user studies to explore the appropriate virtual screen size and positioning under our retargeting method and then compared various drag-and-drop methods for cross-screen interaction. Finally, we compared our method with controller-based interaction in application scenarios.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {1135},
numpages = {17},
keywords = {Virtual reality, 3D user interfaces, haptic retargeting, passive haptics, interaction},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3706599.3706667,
author = {Eriksson, Eva and Costa, Concei\c{c}\~{a}o e and Goncalves, Maria and Nunes, Ines and Groen, Maarten and Niederer, Sabine and Holflod, Kim and N\o{}rg\r{a}rd, Rikke Toft},
title = {Cultural Game Jams with Youth: A Multiple-Site Case Study},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706667},
doi = {10.1145/3706599.3706667},
abstract = {In this paper, we present a multiple-site case study to illustrate the similarities and differences in cultural game jam design with youth in situated research contexts. The aim is to provide the reader with an insight into the problem space, jam design, outcomes and opportunities of a set of linked, yet individual, studies from several different contexts and countries. The cases provide a platform to think about how game jam studies might be collectively reported and evaluated even when they are carried out in different ways. The contribution is an illustration of differentiated replication in multiple cultural game jam studies with youth in different countries. The reflections on replication and differentiation is of interest for cultural game jam activities to empower youth’s cultural participation through technology design.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {666},
numpages = {8},
keywords = {Game jam, culture, values, design, digital games},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706599.3720214,
author = {Adiwangsa, Michelle and Suominen, Hanna and Sweetser, Penny},
title = {Can Augmented Reality Head-Mounted Display Exergames Support the Management of Multiple Sclerosis at Home? Workshop Discussions with Researchers and Experts with Lived Experience of MS},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3720214},
doi = {10.1145/3706599.3720214},
abstract = {Exercising is a beneficial rehabilitation strategy for people with Multiple Sclerosis (MS). Exergaming provides an alternative to traditional rehabilitation programs, increasing accessibility and adherence to home-based exercise. Augmented reality (AR) head-mounted displays (HMDs) offer a promising solution for safer and more inclusive in-home exergaming experiences, which is important for people with MS. However, research on AR HMDs for exergaming in MS rehabilitation is still limited and evolving. It is still unclear whether these systems are suitable for supporting physical rehabilitation, particularly in managing MS at home. To investigate, we conducted an online workshop with eight multidisciplinary researchers and experts with lived experience of MS conducting research in MS and related technologies. We produced themes relating to accessibility and equipment considerations, and the importance of social interaction. We present our key findings from the workshop and offer recommendations for using AR HMD exergames in the rehabilitation of MS.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {124},
numpages = {7},
keywords = {Augmented reality, Exercising, Exergaming, Home environment, Participatory Design},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3706598.3713089,
author = {Yu, Difeng and Roberts, James and Hornb\ae{}k, Kasper and Bergstr\"{o}m, Joanna},
title = {Deriving Selection Techniques for GUIs based on the Multiple Process Model},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713089},
doi = {10.1145/3706598.3713089},
abstract = {Designing efficient selection techniques for graphical user interfaces (GUIs) is fundamental in HCI research. We derive selection techniques based on the multiple process model, a theory that details the motor control processes during goal-directed movements. Specifically, we deduce three theoretical assumptions on how control processes of pre-planning, impulse control, and limb-target control could influence selection movements when adjusting GUI elements, including visual feedback, cursor position, and target position. Corresponding to our assumptions, we develop three techniques that hide the cursor when a target is highlighted, snap the cursor when selection begins, and expand clustered objects during selection movements. After that, we pre-register the assumptions and research methodology and evaluate the techniques in three crowdsourcing-based pointing studies. Our results show that all techniques improved the selection efficiency compared to established baselines. We further discuss the design implications and reflect on how we derived techniques from theory.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {851},
numpages = {16},
keywords = {Cursor, input, object selection, pointing, target selection},
location = {
},
series = {CHI '25}
}

@inproceedings{10.1145/3613905.3637143,
author = {Read, Janet and Sim, Gavin and Fails, Jerry Alan and Boden, Marie A and Korte, Jessica L and Bhatnagar, Sanjana and Hope Borchardt, Lilly and Constantin, Aurora and Gavrilescu, Dina and Wilson, Cara and Good, Judith and Andries, Valentina and Eriksson, Eva},
title = {Exploring Similarities and Differences in a set of Linked Multiple-site Design Sessions with Children},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3637143},
doi = {10.1145/3613905.3637143},
abstract = {In this paper, we present a multiple-site case study to illustrate the similarities and differences in design with children in situated research contexts. The aim is to provide the reader with an insight into the planning, execution and evaluation of a set of linked, yet individual, studies from several different contexts and countries. The cases provide a platform to think about how design studies might be collectively reported and evaluated even when they are carried out in different ways. We illustrate the inherent complexity of this process by considering six case studies from five countries on three continents. The contribution is an illustration of differentiated replication in multiple distributed participatory design case studies with children in different countries. We share our thoughts on replication and differentiation, on the value of the design activities, and on how to carry out a larger project.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {519},
numpages = {9},
keywords = {Case study, Child-computer interaction, Co-design, Distributed participatory design},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3613904.3641899,
author = {Reza, Mohi and Laundry, Nathan M and Musabirov, Ilya and Dushniku, Peter and Yu, Zhi Yuan “Michael” and Mittal, Kashish and Grossman, Tovi and Liut, Michael and Kuzminykh, Anastasia and Williams, Joseph Jay},
title = {ABScribe: Rapid Exploration &amp; Organization of Multiple Writing Variations in Human-AI Co-Writing Tasks using Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3641899},
doi = {10.1145/3613904.3641899},
abstract = {Exploring alternative ideas by rewriting text is integral to the writing process. State-of-the-art Large Language Models (LLMs) can simplify writing variation generation. However, current interfaces pose challenges for simultaneous consideration of multiple variations: creating new variations without overwriting text can be difficult, and pasting them sequentially can clutter documents, increasing workload and disrupting writers’ flow. To tackle this, we present ABScribe, an interface that supports rapid, yet visually structured, exploration and organization of writing variations in human-AI co-writing tasks. With ABScribe, users can swiftly modify variations using LLM prompts, which are auto-converted into reusable buttons. Variations are stored adjacently within text fields for rapid in-place comparisons using mouse-over interactions on a popup toolbar. Our user study with 12 writers shows that ABScribe significantly reduces task workload (d = 1.20, p &lt; 0.001), enhances user perceptions of the revision process (d = 2.41, p &lt; 0.001) compared to a popular baseline workflow, and provides insights into how writers explore variations using LLMs.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {1042},
numpages = {18},
keywords = {datasets, gaze detection, neural networks, text tagging},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3544548.3581180,
author = {Grundgeiger, Tobias and M\"{u}nz, Alea and Schlosser, Paul and Happel, Oliver},
title = {Supervising Multiple Operating Rooms Using a Head-Worn display: A Longitudinal Evaluation of the Experience of Supervising Anesthesiologists and Their Co-Workers},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581180},
doi = {10.1145/3544548.3581180},
abstract = {Research has explored head-worn displays (HWD) in various professional contexts. However, evaluations have been limited by short-term use, a focus on the person using the HWD, and on performance variables. In a field study, we evaluated a monocular, opaque HWD for multi-patient monitoring, which supervising anesthesiologists wore for 8-10 days each. We investigated the effect of prolonged HWD use on the experience of the supervising anesthesiologists and their co-workers using interviews and repeated observations. A reflexive thematic analysis showed (1) interaction and mindset changes over time, (2) information on the HWD is more than numbers, (3) the HWD affects co-workers' collaboration with supervisors, and (4) distraction depends on the point of view. Using activity theory, we discuss the fact that HWD use develops and changes over time and that even a single-user HWD influences the collaboration with co-workers. We conclude with implications for HWD design, implementation, and evaluation.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {345},
numpages = {18},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/2559206.2574835,
author = {Tang, Yichen and Stavness, Ian and Fels, Sidney S.},
title = {The new pCubee: multi-touch perspective-corrected cubic display},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2574835},
doi = {10.1145/2559206.2574835},
abstract = {We present the latest revision of our personal perspective-corrected hand-held cubic display, pCubee, featuring a complete hardware redesign and novel interaction mechanisms. The OLED panels introduce improved visual experience for users, and allow a lightweight and compact design that makes the system easy to manipulate. Users can interact with virtual objects in the display through various methods including real-time physics simulation, directly-mapped stylus and cross-screen multi-touch input. Applications of the technology include visualization for static or dynamic contents, 3D object manipulation and tangible entertainment.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {419–422},
numpages = {4},
keywords = {user interface, hand-held device, fish tank virtual reality, displays, bimanual interaction},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@inproceedings{10.1145/3544548.3581185,
author = {Oyshi, Marzan Tasnim and Vogt, Sebastian and Gumhold, Stefan},
title = {TmoTA: Simple, Highly Responsive Tool for Multiple Object Tracking Annotation},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581185},
doi = {10.1145/3544548.3581185},
abstract = {Machine learning is applied in a multitude of sectors with very impressive results. This success is due to the availability of an ever-growing amount of data acquired by omnipresent sensor devices and platforms on the internet. But there is a scarcity of labeled data which is required for most ML methods. However, generation of labeled data requires much time and resources. In this paper, we propose a portable, Open Source, simple and responsive manual Tool for 2D multiple object Tracking Annotation (TmoTA). Besides responsiveness, our tool design provides several features like view centering and looped playback that speed up the annotation process. We evaluate our proposed tool by comparing TmoTA with the widely used manual labeling tools CVAT, Label Studio, and two semi-automated tools Supervisely and VATIC with respect to object labeling time and accuracy. The evaluation includes a user study and pre-case studies showing that the annotation time per object frame can be reduced by 20% to 40% over the first 20 annotated objects compared to the manual labeling tools.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {413},
numpages = {11},
keywords = {data labeling, manual labeling, video sequence labeling},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581124,
author = {Barbareschi, Giulia and Kawaguchi, Midori and Kato, Hiroaki and Nagahiro, Masato and Takeuchi, Kazuaki and Shiiba, Yoshifumi and Kasahara, Shunichi and Kunze, Kai and Minamizawa, Kouta},
title = {“I am both here and there” Parallel Control of Multiple Robotic Avatars by Disabled Workers in a Caf\'{e}},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581124},
doi = {10.1145/3544548.3581124},
abstract = {Robotic avatars can help disabled people extend their reach in interacting with the world. Technological advances make it possible for individuals to embody multiple avatars simultaneously. However, existing studies have been limited to laboratory conditions and did not involve disabled participants. In this paper, we present a real-world implementation of a parallel control system allowing disabled workers in a caf\'{e} to embody multiple robotic avatars at the same time to carry out different tasks. Our data corpus comprises semi-structured interviews with workers, customer surveys, and videos of caf\'{e} operations. Results indicate that the system increases workers’ agency, enabling them to better manage customer journeys. Parallel embodiment and transitions between avatars create multiple interaction loops where the links between disabled workers and customers remain consistent, but the intermediary avatar changes. Based on our observations, we theorize that disabled individuals possess specific competencies that increase their ability to manage multiple avatar bodies.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {75},
numpages = {17},
keywords = {avatar, caf\'{e}, disability, telework},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580731,
author = {Tseng, Fang-Ching and Chiou, Zih-Yun and Chuang, Ho-Hsuan and Su, Li-Ting and Lin, Yong-Han and Lin, Yu-Rou and Lee, Yi-Chi and Wang, Peng-Jui and Chen, Uei-Dar and Chang, Yung-Ju},
title = {Multiple Device Users’ Actual and Ideal Cross-Device Usage for Multi-Stage Notification-Interactions: An ESM Study Addressing the Usage Gap and Impacts of Device Context},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580731},
doi = {10.1145/3544548.3580731},
abstract = {People nowadays can use multiple devices to interact with notifications, whether via noticing, glancing, reading, or acting upon them. Prior research has focused on actual usage or on device preferences. However, users’ ideal experience of cross-device notification-interaction might differ from their current practices (due to situational limitations) and/or across the four notification-interaction stages. We therefore conducted an experience-sampling method study with multi-device users to investigate these gaps and the influence of device context. Our results reveal that nearly half of the time, the non-phone devices the participants had ranked as their top preferences for notification-interaction were not actually used, due to the devices’ context. Beyond device context, the participants’ choices of devices for notification-interaction were heavily determined by 1) their preferences that particular notification-interaction stages to take place (or not) on particular devices; and 2) the device on which they had undertaken the former stage.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {649},
numpages = {15},
keywords = {Experience Sampling Method, Multi-Device, Notifications},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580727,
author = {Han, Sangyoon and Park, Jaejun and Choi, Seungmoon},
title = {Generating Haptic Motion Effects for Multiple Articulated Bodies for Improved 4D Experiences: A Camera Space Approach},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580727},
doi = {10.1145/3544548.3580727},
abstract = {Motion effects are indispensable for improving 4D experiences in highly interactive applications, such as amusement parks, 4D theaters, and virtual reality games. Their recent emergence calls for effective algorithms generating motion effects synchronized with audiovisual content. This paper presents an automatic algorithm for synthesizing the object-based motion effects that express the movements of multiple articulated bodies inclusively when the objects’ motion trajectories are available in the 3D camera space. By taking the visual velocities and sizes of all object parts, our method computes a motion proxy that represents the objects’ movements by one point and converts the motion proxy to a motion command through a motion cueing algorithm. The motion proxy is determined by linearly combining the velocities, and its best combination was selected from several candidates by user studies. The results of user studies indicate that our algorithm can produce compelling object-based motion effects that enhance the multisensory experience.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {17},
keywords = {4D, articulated body, automatic generation, haptics, motion cueing, motion effects, mulsemedia, multiple sensorial media, synthesis, vestibular sense, virtual reality},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3580908,
author = {Ryu, Hyeyoung and Berry, Andrew B.L. and Lim, Catherine Y and Hartzler, Andrea and Hirsch, Tad and Trejo, Juanita I and Bermet, Zo\"{e} Abigail and Crawford-Gallagher, Brandi and Tran, Vi and Ferguson, Dawn and Cronkite, David J and Tiffany, Brooks and Weeks, John and Ralston, James},
title = {“You Can See the Connections”: Facilitating Visualization of Care Priorities in People Living with Multiple Chronic Health Conditions},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580908},
doi = {10.1145/3544548.3580908},
abstract = {Individuals with multiple chronic health conditions (MCC) often face an overwhelming set of self-management work, resulting in a need to set care priorities. Yet, much self-management work is invisible to healthcare providers. This study aimed to understand how to support the development and sharing of connections between personal values and self-management tasks through the facilitated use of an interactive visualization system: Conversation Canvas. We conducted a field study with 13 participants with MCC, 3 caregivers, and 7 primary care providers in Washington State. Analysis of interviews with MCC participants showed that developing visualizations of connections between personal values, self-management tasks, and health conditions helped individuals make sense of connections relevant to their health and wellbeing, recognize a road map of central issues and their impacts, feel respected and understood, share priorities with providers, and support value-aligned changes. These findings demonstrated potential for the guided process and visualization to support priorities-aligned care.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {473},
numpages = {17},
keywords = {multiple chronic health conditions, patient priorities care, patient-clinician communication, reflection, sensemaking, values, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3544548.3581514,
author = {Anwar, Ahmed and Shi, Tianzheng and Schneider, Oliver},
title = {Factors of Haptic Experience across Multiple Haptic Modalities},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581514},
doi = {10.1145/3544548.3581514},
abstract = {Haptic Experience (HX) is a proposed set of quality criteria useful to haptics, with prior evidence for a 5-factor model with vibrotactile feedback. We report on an ongoing process of scale development to measure HX, and explore whether these criteria hold when applied to more diverse devices, including vibrotactile, force feedback, surface haptics, and mid-air haptics. From an in-person user study with 430 participants, exploratory factor analysis (EFA), and confirmatory factor analysis (CFA), we extract an 11-item and 4-factor model (Realism, Harmony, Involvement, Expressivity) with only a partial overlap to the previous model. We compare this model to the previous vibrotactile model, finding that the new 4-factor model is more generalized and can guide attributes or applications of new haptic systems. Our findings suggest that HX may vary depending on the modalities used in an application, but these four factors are general constructs that might overlap with modality-specific concepts of HX. These factors can inform designers about the right quality criteria to use when designing or evaluating haptic experiences for multiple modalities.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {260},
numpages = {12},
keywords = {HCI, Haptics, Scale Development, User experience design},
location = {Hamburg, Germany},
series = {CHI '23}
}

@inproceedings{10.1145/3139491.3139501,
author = {Trabelsi, Rim and Varadarajan, Jagannadan and Pei, Yong and Zhang, Le and Jabri, Issam and Bouallegue, Ammar and Moulin, Pierre},
title = {Multi-modal social interaction recognition using view-invariant features},
year = {2017},
isbn = {9781450355582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3139491.3139501},
doi = {10.1145/3139491.3139501},
abstract = {This paper addresses the issue of analyzing social interactions between humans in videos. We focus on recognizing dyadic human interactions through multi-modal data, specifically, depth, color and skeleton sequences. Firstly, we introduce a new person-centric proxemic descriptor, named PROF, extracted from skeleton data able to incorporate intrinsic and extrinsic distances between two interacting persons in a view-variant scheme. Then, a novel key frame selection approach is introduced to identify salient instants of the interaction sequence based on the joint energy. From RGBD videos, more holistic CNN features are extracted by applying an adaptive pre-trained CNNs on optical flow frames. Features from three modalities are combined then classified using linear SVM. Finally, extensive experiments have been carried on two multi-modal and multi-view interactions datasets prove the robustness of the introduced approach comparing to state-of-the-art methods.},
booktitle = {Proceedings of the 1st ACM SIGCHI International Workshop on Investigating Social Interactions with Artificial Agents},
pages = {47–48},
numpages = {2},
keywords = {Social Interaction, Multi-modal data, Multi-View},
location = {Glasgow, UK},
series = {ISIAA 2017}
}

@inproceedings{10.1145/1978942.1979313,
author = {Bakke, Eirik and Karger, David and Miller, Rob},
title = {A spreadsheet-based user interface for managing plural relationships in structured data},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979313},
doi = {10.1145/1978942.1979313},
abstract = {A key feature of relational database applications is managing emph{plural} relationships---one-to-many and many-to-many---between entities. However, since it is often infeasible to adopt or develop a new database application for any given schema at hand, information workers instead turn to spreadsheets, which lend themselves poorly to schemas requiring multiple related entity sets. In this paper, we propose to reduce the cost-usability gap between spreadsheets and tailor-made relational database applications by extending the spreadsheet paradigm to let the user establish relationships between rows in related worksheets as well as view and navigate the hierarchical cell structure that arises as a result. We present Related Worksheets, a spreadsheet-like prototype application, and evaluate it with a screencast-based user study on 36 Mechanical Turk workers. First-time users of our software were able to solve lookup-type query tasks with the same or higher accuracy as subjects using Microsoft Excel, in one case 40% faster on average.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2541–2550},
numpages = {10},
keywords = {spreadsheets, one-to-many relationships, hierarchical views, foreign key relationships, databases},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/3491101.3516387,
author = {Tsukuda, Yuga and Tagami, Daichi and Sadasue, Masaaki and Suzuki, Shieru and Lu, Jun-Li and Ochiai, Yoichi},
title = {Calmbots: Exploring Possibilities of Multiple Insects with On-hand Devices and Flexible Controls as Creation Interfaces},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3516387},
doi = {10.1145/3491101.3516387},
abstract = {We introduce ”Calmbots” that are insects-based interfaces comprising multiple functions, i.e., drawing, display, transportation, or haptics. We explore possibilities of multiple insects as co-creation interfaces making artworks through insects indirectly, in contrast with BioArt where artworks are made by biological technology. Considering scalability, sustainability, or promotability of applying insects-based devices on creation activities in daily life situations, we utilize on-hand and efficient control system by AR markers and radio-based station, and propose efficient ways of controlling multiple insects reaching goals and transporting objects, and customize flexible option parts. In robust experimental trials, our results showed effective control on a group of three or five cockroaches with at-least 60% reaching accuracy, mobility on carpeted or cable-lines floor, and possible continuous control under certain time duration. Participants in a user study felt positive with Calmbots’ functions and expected more performance or appearance on activities or creation in daily life.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {9},
numpages = {13},
keywords = {Interfaces of Multiple Insects, Insect-based Creation},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3491102.3501873,
author = {Schjerlund, Jonas and Hornb\ae{}k, Kasper and Bergstr\"{o}m, Joanna},
title = {OVRlap: Perceiving Multiple Locations Simultaneously to Improve Interaction in VR},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501873},
doi = {10.1145/3491102.3501873},
abstract = {We introduce OVRlap, a VR interaction technique that lets the user perceive multiple places at the same time from a first-person perspective. OVRlap achieves this by overlapping viewpoints. At any time, only one viewpoint is active, meaning that the user may interact with objects therein. Objects seen from the active viewpoint are opaque, whereas objects seen from passive viewpoints are transparent. This allows users to perceive multiple locations at once and easily switch to the one in which they want to interact. We compare OVRlap and a single-viewpoint technique in a study where 20 participants complete object-collection and monitoring tasks. We find that in both tasks, participants are significantly faster and move their head significantly less with OVRlap. We propose how the technique might be improved through automated switching of the active viewpoint and intelligent viewpoint rendering.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {355},
numpages = {13},
keywords = {interaction techniques, large environments, user studies, virtual reality},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491101.3516800,
author = {Chen, Eason},
title = {The Effect of Multiple Replies for Natural Language Generation Chatbots},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3516800},
doi = {10.1145/3491101.3516800},
abstract = {In this research, by responding to users’ utterances with multiple replies to create a group chat atmosphere, we alleviate the problem that Natural Language Generation chatbots might reply with inappropriate content, thus causing a bad user experience. Because according to our findings, users tend to pay attention to appropriate replies and ignore inappropriate replies. We conducted a 2 (single reply vs. five replies) \texttimes{} 2 (anonymous avatar vs. anime avatar) repeated measures experiment to compare the chatting experience in different conditions. The result shows that users will have a better chatting experience when receiving multiple replies at once from the NLG model compared to the single reply. Furthermore, according to the effect size of our result, to improve the chatting experience for NLG chatbots which is single reply and anonymous avatar, providing five replies will have more benefits than setting an anime avatar.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {469},
numpages = {5},
keywords = {Natural Language Generation, Multiple Replies, Improve Chatting Experience, Chatbot},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3491102.3501967,
author = {Rechkemmer, Amy and Yin, Ming},
title = {When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501967},
doi = {10.1145/3491102.3501967},
abstract = {Previous research shows that laypeople’s trust in a machine learning model can be affected by both performance measurements of the model on the aggregate level and performance estimates on individual predictions. However, it is unclear how people would trust the model when multiple performance indicators are presented at the same time. We conduct an exploratory human-subject experiment to answer this question. We find that while the level of model confidence significantly affects people’s belief in model accuracy, both the model’s stated and observed accuracy generally have a larger impact on people’s willingness to follow the model’s predictions as well as their self-reported levels of trust in the model, especially after observing the model’s performance in practice. We hope the empirical evidence reported in this work could open doors to further studies to advance understanding of how people perceive, process, and react to performance-related information of machine learning.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {535},
numpages = {14},
keywords = {Machine learning, accuracy, confidence, human-subject experiments, trust},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3502141,
author = {Dang, Hai and Mecke, Lukas and Buschek, Daniel},
title = {GANSlider: How Users Control Generative Models for Images using Multiple Sliders with and without Feedforward Information},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502141},
doi = {10.1145/3491102.3502141},
abstract = {We investigate how multiple sliders with and without feedforward visualizations influence users’ control of generative models. In an online study (N=138), we collected a dataset of people interacting with a generative adversarial network (StyleGAN2) in an image reconstruction task. We found that more control dimensions (sliders) significantly increase task difficulty and user actions. Visual feedforward partly mitigates this by enabling more goal-directed interaction. However, we found no evidence of faster or more accurate task performance. This indicates a tradeoff between feedforward detail and implied cognitive costs, such as attention. Moreover, we found that visualizations alone are not always sufficient for users to understand individual control dimensions. Our study quantifies fundamental UI design factors and resulting interaction behavior in this context, revealing opportunities for improvement in the UI design for interactive applications of generative models. We close by discussing design directions and further aspects.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {569},
numpages = {15},
keywords = {dataset, generative adversarial network, image manipulation, interactive AI, user study},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3491102.3501989,
author = {Seals, Ayanna and Pilloni, Giuseppina and Kim, Jin and Sanchez, Raul and Rizzo, John-Ross and Charvet, Leigh and Nov, Oded and Dove, Graham},
title = {‘Are They Doing Better In The Clinic Or At Home?’: Understanding Clinicians’ Needs When Visualizing Wearable Sensor Data Used In Remote Gait Assessments For People With Multiple Sclerosis},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3501989},
doi = {10.1145/3491102.3501989},
abstract = {Walking impairment is a debilitating symptom of Multiple Sclerosis (MS), a disease affecting 2.8 million people worldwide. While clinicians’ in-person observational gait assessments are important, research suggests that data from wearable sensors can indicate early onset of gait impairment, track patients’ responses to treatment, and support remote and longitudinal assessment. We present an inquiry into supporting the transition from research to clinical practice. Co-design by HCI, biomedical, neurology and rehabilitation researchers resulted in a data-rich interface prototype for augmented gait analysis based on visualized sensor data. We used this as a prompt in interviews with ten experienced clinicians from a range of MS rehabilitation roles. We find that clinicians value quantitative sensor data within a whole patient narrative, to help track specific rehabilitation goals, but identify a tension between grasping critical information quickly and more detailed understanding. Based on the findings we make design recommendations for data-rich remote rehabilitation interfaces.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {350},
numpages = {16},
keywords = {data visualization, gait assessments, multiple sclerosis, remote care, transition to clinical practice, wearables},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3411764.3445530,
author = {Jung, Jingun and Son, Sunmin and Lee, Sangyoon and Kim, Yeonsu and Lee, Geehyuk},
title = {ThroughHand: 2D Tactile Interaction to Simultaneously Recognize and Touch Multiple Objects},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445530},
doi = {10.1145/3411764.3445530},
abstract = {Users with visual impairments find it difficult to enjoy real-time 2D interactive applications on the touchscreen. Touchscreen applications such as sports games often require simultaneous recognition of and interaction with multiple moving targets through vision. To mitigate this issue, we propose ThroughHand, a novel tactile interaction that enables users with visual impairments to interact with multiple dynamic objects in real time. We designed the ThroughHand interaction to utilize the potential of the human tactile sense that spatially registers both sides of the hand with respect to each other. ThroughHand allows interaction with multiple objects by enabling users to perceive the objects using the palm while providing a touch input space on the back of the same hand. A user study verified that ThroughHand enables users to locate stimuli on the palm with a margin of error of approximately 13&nbsp;mm and effectively provides a real-time 2D interaction experience for users with visual impairments.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {13},
keywords = {Visual impairments, Shape-changing display, Real-time interaction, Haptics, Games, Accessibility},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3411763.3450387,
author = {Pataranutaporn, Pat and Danry, Valdemar and Maes, Pattie},
title = {Machinoia, Machine of Multiple Me: Integrating with Past, Future and Alternative Selves},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3450387},
doi = {10.1145/3411763.3450387},
abstract = {Our body and mind relate in ways which are extraordinarily enigmatic and seemingly incomprehensible. Recent findings exemplify this by showing not just that our minds can phenomenologically inhabit multiple bodies but also that our body can be accessed by multiple minds. As an exploration of this concept, we present Machinoia, a symbiotic augmentation that extends the user with two additional heads each of which are unique variations of the users identity: who you once were, and who you’ll eventually become. We used a generative adversarial network to synthesize life-like human faces and controlled them through artificial attitude models extracted from social media data of the wearer, thus creating “artificial personal intelligences” of the wearer, bringing to life past and future versions of oneself.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {26},
numpages = {7},
keywords = {artificial intelligence, human enhancement, human-computer integration, philosophy of mind, wearable technology},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451794,
author = {Sandnes, Frode Eika},
title = {HIDE: Short IDs for Robust and Anonymous Linking of Users Across Multiple Sessions in Small HCI Experiments},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451794},
doi = {10.1145/3411763.3451794},
abstract = {Record linking is needed to analyze observations across multiple sessions. However, recent privacy legislature such as the General Data Protection Regulations (GDPR) restricts the storage of information that identify individuals. Obtaining permissions to store information about individuals can be bureaucratic and time-consuming. Anonymous schemes such as self-generated ids and machine generated ids have been proposed. However, self-generated linking ids demand effort from the participants, while machine assisted schemes typically generate long and incomprehensible ids. Consequently, there is a risk that students and researchers will limit their research to single-session experiments to avoid privacy issues. To simplify the administration of small multi-session experiments, the HIDE procedure is proposed for generating short human readable ids for linking participants across multiple sessions while maintaining anonymity and being robust to input errors. The approach is different from previous approaches in that the goal is to minimize the length of the linking ids. First, the procedure converts the participant's name into a phonetic representation. Next, this phonetic representation is hashed, and a truncated snippet of the hash is used as the linking id. HIDE is initialized by searching for a salt (a random data added to the hash input) that minimizes the id lengths. Experiments show that the procedure is capable of coding small experiments with 20 participants using two digits, and experiments of around 200 participants with four digits. An implementation of the procedure has been made available through a simple web interface. It is hoped that the procedure can help students and HCI researchers collect more comprehensive data by following participants over time, while protecting their privacy.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {326},
numpages = {6},
keywords = {GDPR, Hashing, Longitudinal studies, Multi session experiments, Privacy, Record linking, Soundex},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411763.3451797,
author = {Neidlinger, Kristin and Koenderink, Stephanie and Truong, Khiet P.},
title = {Give the Body a Voice: Co-design with Profound Intellectual and Multiple Disabilities to Create Multisensory Wearables},
year = {2021},
isbn = {9781450380959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411763.3451797},
doi = {10.1145/3411763.3451797},
abstract = {This study explores non-verbal co-design techniques with multisensory wearables to give the body a voice. Sessions were led with professional caregivers, parents, and clients with PIMD (profound intellectual and multiple disabilities) to find fundamental building blocks for a common language based on tangible technologies. To provide an agent for communication we employed the tools of extimacy - translating biodata to visual, auditory, or tactile interactive displays. The caregivers expressed the need for action – reaction “Actie Reactie” to keep attention, which was an update from the Multisensory Environment (MSE) rooms previously used to calm. In the co-design sessions, we found the on-the-body wearables held the most focus. The final discovery from the study became the outline for creating a modular, highly personalized kit for a Multisensory Wearable (MSW) to inspire surprise and wonder.},
booktitle = {Extended Abstracts of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {375},
numpages = {6},
keywords = {PIMD, biosensing, co-design, extimacy, multisensory, non-verbal, wearable},
location = {Yokohama, Japan},
series = {CHI EA '21}
}

@inproceedings{10.1145/3411764.3445372,
author = {Buschek, Daniel and Z\"{u}rn, Martin and Eiband, Malin},
title = {The Impact of Multiple Parallel Phrase Suggestions on Email Input and Composition Behaviour of Native and Non-Native English Writers},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445372},
doi = {10.1145/3411764.3445372},
abstract = {We present an in-depth analysis of the impact of multi-word suggestion choices from a neural language model on user behaviour regarding input and text composition in email writing. Our study for the first time compares different numbers of parallel suggestions, and use by native and non-native English writers, to explore a trade-off of “efficiency vs ideation”, emerging from recent literature. We built a text editor prototype with a neural language model (GPT-2), refined in a prestudy with 30 people. In an online study (N=156), people composed emails in four conditions (0/1/3/6 parallel suggestions). Our results reveal (1) benefits for ideation, and costs for efficiency, when suggesting multiple phrases; (2) that non-native speakers benefit more from more suggestions; and (3) further insights into behaviour patterns. We discuss implications for research, the design of interactive suggestion systems, and the vision of supporting writers with AI instead of replacing them.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {732},
numpages = {13},
keywords = {typing, text suggestions, neural network, language model, deep learning, dataset, Text entry},
location = {Yokohama, Japan},
series = {CHI '21}
}

@inproceedings{10.1145/3290605.3300874,
author = {Boukhelifa, Nadia and Bezerianos, Anastasia and Trelea, Ioan Cristian and Perrot, Nathalie M\'{e}jean and Lutton, Evelyne},
title = {An Exploratory Study on Visual Exploration of Model Simulations by Multiple Types of Experts},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300874},
doi = {10.1145/3290605.3300874},
abstract = {Experts in different domains rely increasingly on simulation models of complex processes to reach insights, make decisions, and plan future projects. These models are often used to study possible trade-offs, as experts try to optimise multiple conflicting objectives in a single investigation. Understanding all the model intricacies, however, is challenging for a single domain expert. We propose a simple approach to support multiple experts when exploring complex model results. First, we reduce the model exploration space, then present the results on a shared interactive surface, in the form of a scatterplot matrix and linked views. To explore how multiple experts analyse trade-offs using this setup, we carried out an observational study focusing on the link between expertise and insight generation during the analysis process. Our results reveal the different exploration strategies and multi-storyline approaches that domain experts adopt during trade-off analysis, and inform our recommendations for collaborative model exploration systems.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {visualization, trade-off analysis, scatterplot matrix, qualitative study, model exploration, insight, expertise, common ground, collaboration},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3334480.3383010,
author = {Kurogi, Tadatoshi and Yonehara, Yuji and Sago, Genki and Shimada, Masatoshi and Fujiwara, Takeshi and Peiris, Roshan Lalintha},
title = {Small, Soft, Thin, Lightweight and Flexible Tactile Display Enabling to Provide Multiple Mechanical Stimuli},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3383010},
doi = {10.1145/3334480.3383010},
abstract = {We propose a small, soft, thin, lightweight, and flexible tactile display consisting of just a single actuator that can provide multiple, mechanical tactile stimuli such as vibration and heating. Various other tactile displays require the usage of multiple actuators such as motors, voice coils, speakers, Peltier elements, and heaters. However, our proposed tactile display uses just one actuator, the Dielectric Elastomer Actuator (DEA), to output vibration and heating. By configuring a tactile display with a DEA, our proposed tactile display can become very small, soft, thin, lightweight, and flexible while being able to output multiple mechanical stimuli. We describe the design of the prototype, control method for the output vibration and heating, advantages and disadvantages of this concept, and discuss future applications.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {DEA, haptic interface, interactive device, tactile display, thermal feedback},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3313831.3376422,
author = {Larsen-Ledet, Ida and Korsgaard, Henrik and B\o{}dker, Susanne},
title = {Collaborative Writing Across Multiple Artifact Ecologies},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376422},
doi = {10.1145/3313831.3376422},
abstract = {Research focusing on how collaborative writing takes place across multiple applications and devices and over longer projects is sparse. We respond to this gap by presenting the results of a qualitative study of longer-term academic writing projects, showing how co-writers employ multiple tools when working on a common text. We identify three patterns of multi-application collaboration as well as four common types of motivations for transitions between applications. We also extend existing taxonomies of collaborative writing by proposing a categorization of the functions served by the text as object and backbone of the collaboration. Together, these contributions offer a framing for understanding transitions within and across artifact ecologies in work around a common object. Our findings highlight ways in which features like concurrent editing may in fact challenge the collaborative writing process, and we point to opportunities for alternative application models.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {academic writing, aligned artifact ecology, artifact ecology, collaboration, collaborative academic writing, collaborative writing, computer-supported cooperative work, cscw, github, google docs, latex, overleaf, personal artifact ecology, potential artifact ecology, sharelatex, text function},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3290605.3300700,
author = {Berry, Andrew B. L. and Lim, Catherine Y. and Hirsch, Tad and Hartzler, Andrea L. and Kiel, Linda M. and Bermet, Zo\"{e} A. and Ralston, James D.},
title = {Supporting Communication About Values Between People with Multiple Chronic Conditions and their Providers},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300700},
doi = {10.1145/3290605.3300700},
abstract = {People with multiple chronic conditions (MCC) often disagree with healthcare providers on priorities for care, leading to worse health outcomes. To align priorities, there is a need to support patient-provider communication about what patients consider important for their well-being and health (i.e., their personal values). To address barriers to communication about values, we conducted a two-part study with key stakeholders in MCC care: patients, informal caregivers, and providers. In Part I, co-design activities generated seven dimensions that characterize stakeholders' diverse ideas for supporting communication about values: explicitness, effort, disclosure, guidance, intimacy, scale, and synchrony. In Part II, we used the dimensions to generate three design concepts and presented them in focus groups to further scrutinize findings from Part I. Based on these findings we outline directions for research and design to improve patient-provider communication about patients' personal values.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {patient-provider communication, multiple chronic conditions, multimorbidity, co-design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300357,
author = {G\"{u}ldenpfennig, Florian and Mayer, Peter and Panek, Paul and Fitzpatrick, Geraldine},
title = {An Autonomy-Perspective on the Design of Assistive Technology Experiences of People with Multiple Sclerosis},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300357},
doi = {10.1145/3290605.3300357},
abstract = {In HCI and Assistive Technology design, autonomy is regularly equated with independence. This is a shortcut and leaves out design opportunities by omitting a more nuanced idea of autonomy. To improve our understanding of how people with severe physical disabilities experience autonomy, particularly in the context of Assistive Technologies, we engaged in in-depth fieldwork with 15 people with Multiple Sclerosis who were used to assistive devices. We constructed a grounded theory from a series of interviews, focus groups and observations, pointing to strategies in which participants sought autonomy either in the short-term (managing their daily energy reserve) or in the long-term (making future plans). The theory shows how factors like enabling technologies, capital (human, social, psychological resources), and compatibility with daily practices facilitated a sense of being in control for our participants. Moreover, we show how over-ambitious or bad design (e.g., paternalism) can lead to opposite results and restrict autonomy.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {robotic toilet, multiple sclerosis, grounded theory, autonomy, ambient assisted living, active and assisted living},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3173574.3173765,
author = {Chaves, Ana Paula and Gerosa, Marco Aurelio},
title = {Single or Multiple Conversational Agents? An Interactional Coherence Comparison},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173765},
doi = {10.1145/3173574.3173765},
abstract = {Chatbots focusing on a narrow domain of expertise are in great rise. As several tasks require multiple expertise, a designer may integrate multiple chatbots in the background or include them as interlocutors in a conversation. We investigated both scenarios by means of a Wizard of Oz experiment, in which participants talked to chatbots about visiting a destination. We analyzed the conversation content, users' speech, and reported impressions. We found no significant difference between single- and multi-chatbots scenarios. However, even with equivalent conversation structures, users reported more confusion in multi-chatbots interactions and adopted strategies to organize turn-taking. Our findings indicate that implementing a meta-chatbot may not be necessary, since similar conversation structures occur when interacting to multiple chatbots, but different interactional aspects must be considered for each scenario.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {human-agent communication, dialog agent, chatbot},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174222,
author = {Sumi, Yasuyuki and Suwa, Masaki and Hanaue, Koichi},
title = {Effects of Viewing Multiple Viewpoint Videos on Metacognition of Collaborative Experiences},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174222},
doi = {10.1145/3173574.3174222},
abstract = {This paper discusses the effects of multiple viewpoint videos for metacognition of experiences. We present a system for recording multiple users' collaborative experiences by wearable and environmental sensors, and another system for viewing multiple viewpoint videos automatically identified and extracted to associate to individual users. We designed an experiment to compare the metacognition of one's own experience between those based on memory and those supported by video viewing. The experimental results show that metacognitive descriptions related to one's own mind, such as feelings and preferences, are possible regardless whether a person is viewing videos, but such episodic descriptions as the content of someone's utterance and what s/he felt associated with it are strongly promoted by video viewing. We conducted another experiment where the same participants did identical metacognitive description tasks about half a year after the previous experiment. Through the experiments, we found the first-person view video is mostly used for confirming the episodic facts immediately after the experience, whereas after half a year, even one's own experience is often felt like the experiences of others therefore the videos capturing themselves from the conversation partners and environment become important for thinking back to the situations where they were placed.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {multiple viewpoint videos, metacognition, experience capturing},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3170427.3188453,
author = {Yao, Nancy and Brewer, Jeff and D'Angelo, Sarah and Horn, Mike and Gergle, Darren},
title = {Visualizing Gaze Information from Multiple Students to Support Remote Instruction},
year = {2018},
isbn = {9781450356213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170427.3188453},
doi = {10.1145/3170427.3188453},
abstract = {Technologically-mediated learning environments are becoming increasingly popular, however remote learning still lacks many of the important interpersonal features that are leveraged in effective co-located learning. Recent work has started to build in non-verbal cues to support remote collaboration, such as showing pairs where their partner is looking on the screen. This method of displaying gaze visualizations has been shown to support coordination and learning in remote collaborative tasks. However, we have yet to explore how this technique scales to support multiple students with one teacher in a technology-mediated learning environment. In this study, we design and evaluate a system for displaying real time gaze information from multiple students to a single teacher's display during a computer science studio session. Our results suggest that multiple gaze visualizations can improve the teaching experience in remote settings. Further, we provide design recommendations for future systems based on our preliminary results.},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {collaboration, eye-tracking, gaze visualizations, learning},
location = {Montreal QC, Canada},
series = {CHI EA '18}
}

@inproceedings{10.1145/3170427.3188460,
author = {Schlosser, Paul and Grundgeiger, Tobias and Happel, Oliver},
title = {Multiple Patient Monitoring in the Operating Room using a Head-Mounted Display},
year = {2018},
isbn = {9781450356213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170427.3188460},
doi = {10.1145/3170427.3188460},
abstract = {Physicians and nurses in intensive care units and operating rooms are responsible for several patients at the same time. However, monitoring multiple patients can be challenging, for example, because staff are moving and vital signs may not be accessible. Therefore, physicians and nurses may not be able to create a full picture of their patients' status - so called situation awareness. The hands-free operability and portability of a head-mounted display could allow physicians and nurses to monitor vital signs constantly and independently of location. We developed an application that displays vital signs of multiple patients on a Vuzix M300 head-mounted display. In this work, we describe the user-centered design approach, implementation, and future evaluation of the application in the operating room at the University Hospital W\"{u}rzburg.},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {head-mounted display, patient monitoring},
location = {Montreal QC, Canada},
series = {CHI EA '18}
}

@inproceedings{10.1145/3173574.3173815,
author = {Marwecki, Sebastian and Brehm, Maximilian and Wagner, Lukas and Cheng, Lung-Pan and Mueller, Florian 'Floyd' and Baudisch, Patrick},
title = {VirtualSpace - Overloading Physical Space with Multiple Virtual Reality Users},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173815},
doi = {10.1145/3173574.3173815},
abstract = {Although virtual reality hardware is now widely available, the uptake of real walking is hindered by the fact that it requires often impractically large amounts of physical space. To address this, we present VirtualSpace, a novel system that allows overloading multiple users immersed in different VR experiences into the same physical space. VirtualSpace accomplishes this by containing each user in a subset of the physical space at all times, which we call tiles; app-invoked maneuvers then shuffle tiles and users across the entire physical space. This allows apps to move their users to where their narrative requires them to be while hiding from users that they are confined to a tile. We show how this enables VirtualSpace to pack four users into 16m2. In our study we found that VirtualSpace allowed participants to use more space and to feel less confined than in a control condition with static, pre-allocated space.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–10},
numpages = {10},
keywords = {virtual reality, real walking, locomotion},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174053,
author = {Zgraggen, Emanuel and Zhao, Zheguang and Zeleznik, Robert and Kraska, Tim},
title = {Investigating the Effect of the Multiple Comparisons Problem in Visual Analysis},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174053},
doi = {10.1145/3173574.3174053},
abstract = {The goal of a visualization system is to facilitate dataset-driven insight discovery. But what if the insights are spurious? Features or patterns in visualizations can be perceived as relevant insights, even though they may arise from noise. We often compare visualizations to a mental image of what we are interested in: a particular trend, distribution or an unusual pattern. As more visualizations are examined and more comparisons are made, the probability of discovering spurious insights increases. This problem is well-known in Statistics as the multiple comparisons problem (MCP) but overlooked in visual analysis. We present a way to evaluate MCP in visualization tools by measuring the accuracy of user reported insights on synthetic datasets with known ground truth labels. In our experiment, over 60% of user insights were false. We show how a confirmatory analysis approach that accounts for all visual comparisons, insights and non-insights, can achieve similar results as one that requires a validation dataset.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {visualization, visual analysis, statistics, multiple comparisons problem, experiment},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3173574.3174198,
author = {Zhang, Xucong and Huang, Michael Xuelin and Sugano, Yusuke and Bulling, Andreas},
title = {Training Person-Specific Gaze Estimators from User Interactions with Multiple Devices},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174198},
doi = {10.1145/3173574.3174198},
abstract = {Learning-based gaze estimation has significant potential to enable attentive user interfaces and gaze-based interaction on the billions of camera-equipped handheld devices and ambient displays. While training accurate person- and device-independent gaze estimators remains challenging, person-specific training is feasible but requires tedious data collection for each target device. To address these limitations, we present the first method to train person-specific gaze estimators across multiple devices. At the core of our method is a single convolutional neural network with shared feature extraction layers and device-specific branches that we train from face images and corresponding on-screen gaze locations. Detailed evaluations on a new dataset of interactions with five common devices (mobile phone, tablet, laptop, desktop computer, smart TV) and three common applications (mobile game, text editing, media center) demonstrate the significant potential of cross-device training. We further explore training with gaze locations derived from natural interactions, such as mouse or touch input.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {multi-devices, appearance-based gaze estimation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3025453.3025923,
author = {Berry, Andrew B. L. and Lim, Catherine and Hartzler, Andrea L. and Hirsch, Tad and Wagner, Edward H. and Ludman, Evette and Ralston, James D.},
title = {How Values Shape Collaboration Between Patients with Multiple Chronic Conditions and Spousal Caregivers},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025923},
doi = {10.1145/3025453.3025923},
abstract = {Individuals with multiple chronic conditions (MCC) collaborate with spousal caregivers daily to pursue what is most important to their health and well-being. Previous research in human-computer interaction has supported individuals with chronic conditions or their caregivers, but little has supported both as a unit. We conducted a field study with 12 patient-caregiver dyads, all married and living together, to identify partners' values and how they shape collaborative management of MCC. Partners' coinciding values motivated them to empathize with and support each other in the face of challenges related to health and well-being. When their values were asymmetric, they perceived tensions between individual autonomy and their ability to coordinate with their partner. Systems to support partners in this context could help them overcome asymmetric values, but should balance this with support for individual autonomy.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {5257–5270},
numpages = {14},
keywords = {self-management, self-care, patient, multiple chronic conditions, coordination, collaboration, caregiver},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/2858036.2858547,
author = {Meng, Weizhi and Li, Wenjuan and Jiang, Lijun and Meng, Liying},
title = {On Multiple Password Interference of Touch Screen Patterns and Text Passwords},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858547},
doi = {10.1145/2858036.2858547},
abstract = {The memorability of multiple passwords is an important topic for user authentication systems. With the advent of Android unlock pattern mechanism, research studies started investigating its usability and security features. This paper presents a study of recalling multiple passwords between text passwords and touch screen unlock patterns, as well as exploring whether users have difficulty in remembering those patterns after a period of time. In our study, participants create unlock patterns for various account scenarios. Our results reveal that participants in the unlock pattern condition with three accounts can outperform those in the text password condition (i.e., achieve higher success rates), not only in a one-hour session (short-term), but also after two weeks (long-term). However, there was no statistically significant difference between participants in the text password and unlock pattern condition in the long-term, when dealing with six accounts.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4818–4822},
numpages = {5},
keywords = {user authentication, usable security, multiple password interference, graphical password, android unlock pattern},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2858036.2858426,
author = {Choi, Koeun and Song, Hyunjoo and Koh, Kyle and Bok, Jinwook and Seo, Jinwook},
title = {Peek-a-View: Smartphone Cover Interaction for Multi-Tasking},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858426},
doi = {10.1145/2858036.2858426},
abstract = {Most smartphones support multi-tasking with several means to switch between apps (e.g., a "recent apps" button or a "back" button). However, switching between apps is cumbersome when one has to do it frequently for example, when notifications keep interrupting one's current task. We introduce Peek-a-View, a fully transparent flipping screen cover that can reduce task switching overhead by providing an additional virtual screen space for subtasks. We assessed its feasibility in handling notifications. Upon receiving a notification, users can peek into the content of the notification without actually switching apps by slightly lifting the cover. If necessary, users can completely flip the cover to switch to the app that fired the notification. Two user studies showed that flipping and peeking interaction provided improved performance and proved to be useful for tasks that involve subtasks.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4658–4662},
numpages = {5},
keywords = {task switching, mobile device, cover interaction},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/3491101.3519816,
author = {Lyu, Haohua and Vachha, Cyrus and Chen, Qianyi and Pyrinis, Odysseus and Liou, Avery and Thoravi Kumaravel, Balasaravanan and Hartmann, Bjoern},
title = {WebTransceiVR: Asymmetrical Communication Between Multiple VR and Non-VR Users Online},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519816},
doi = {10.1145/3491101.3519816},
abstract = {Increasing adoption of Virtual Reality (VR) systems in various fields has created the need for collaborative work and communication. Today, asymmetric communication between a VR user and other non-VR users remains a challenge. The VR user cannot see the external non-VR users, and the non-VR users are restricted to the VR user’s first-person view. To address this, we propose WebTransceiVR, an asymmetric collaboration toolkit which when integrated into a VR application, allows multiple non-VR users to share the virtual space of the VR user. It allows external users to enter and be part of the VR application’s space through standard web browsers on mobile and computers. These external users can explore and interact with the other users, the VR scene as well as the VR user. WebTransceiVR also includes a cloud-based streaming solution that enables many passive spectators to view the scene through any of the active cameras. We conduct informal user testing to gain additional insights for future work.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {313},
numpages = {7},
keywords = {Virtual Reality, Asymmetric Communication},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/2858036.2858221,
author = {Gorinova, Maria I. and Sarkar, Advait and Blackwell, Alan F. and Syme, Don},
title = {A Live, Multiple-Representation Probabilistic Programming Environment for Novices},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858221},
doi = {10.1145/2858036.2858221},
abstract = {We present a live, multiple-representation novice environment for probabilistic programming based on the Infer.NET language. When compared to a text-only editor in a controlled experiment on 16 participants, our system showed a significant reduction in keystrokes during introductory probabilistic programming exercises, and subsequently, a significant improvement in program description and debugging tasks as measured by task time, keystrokes and deletions.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {2533–2537},
numpages = {5},
keywords = {visual languages, probabilistic programming, multiple representation, development environment, computational thinking},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.17210/hcik.2016.01.55,
author = {Huynh, Xuan-Phung and Kim, Yong-Guk},
title = {Deep Learning-based Multiple Pedestrians Detection-Tracking Framework},
year = {2016},
isbn = {9788968487910},
publisher = {Hanbit Media, Inc.},
address = {Seoul, KOR},
url = {https://doi.org/10.17210/hcik.2016.01.55},
doi = {10.17210/hcik.2016.01.55},
abstract = {We propose a new Detection-Tracking (DT) framework whereby one can detect a pedestrian, or multiple ones, with-in a video image and then track them concurrently in a flex-ible manner. For the detection, a faster R-CNN will be used since it has a state-of-the-art detection accuracy as well as speed. For the tracking, we have developed a fast and relia-ble tracker, which mainly consists of Kernelized Correla-tion Filter (KCF) and Kalman filter and shows enhancing performance in the occlusion and human-crossing situations. After the faster R-CNN detects objects' regions and scores for that objects, our tracker estimates object's position based on kernel method and Kalman filter. We demonstrate that the proposed framework can detect and track multiple moving pedestrians concurrently for the walking crowd scene.},
booktitle = {Proceedings of HCI Korea},
pages = {55–60},
numpages = {6},
keywords = {Surveillance, R-CNN, Pedestrian, Kernelized Correlation filter, Kalman filter, Convolutional Neural Network},
location = {Jeongseon, Republic of Korea},
series = {HCIK '16}
}

@inproceedings{10.1145/2702613.2732910,
author = {Manresa-Yee, Cristina and Morrison, Ann and Muntaner, Joan Jordi},
title = {First Insights with a Vibrotactile Interface for Children with Multiple Disabilities},
year = {2015},
isbn = {9781450331463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702613.2732910},
doi = {10.1145/2702613.2732910},
abstract = {Designing and evaluating interactive systems for users with multiple disabilities is a challenge due to their cognitive, sensory, physical and behavioral conditions. Vibrotactile interfaces to motivate users' actions exist for users with hearing and sight impairments, but there are hardly any for users with multiple disabilities. We developed V-Sense, a vibrotactile interface that encourages children with multiple disabilities to move their arms by using vibrations and exploiting the saltation perceptual illusion. In this paper we describe our initial experience evaluating the interface with 5 children for 7 weeks and we discuss the first insights concerning the use of the interface and the difficulties encountered while conducting the evaluation sessions.},
booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {905–910},
numpages = {6},
keywords = {vibrotactile interface, interactive environment, environmental stimulation, children with special needs},
location = {Seoul, Republic of Korea},
series = {CHI EA '15}
}

@inproceedings{10.1145/2702123.2702211,
author = {Jokela, Tero and Ojala, Jarno and Olsson, Thomas},
title = {A Diary Study on Combining Multiple Information Devices in Everyday Activities and Tasks},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702211},
doi = {10.1145/2702123.2702211},
abstract = {As people possess increasing numbers of information devices, situations where several devices are combined and used together have become more common. We present a user study on people's current practices in combining multiple information devices in their everyday lives, ranging from pragmatic tasks to leisure activities. Based on diaries and interviews of 14 participants, we characterize the usage practices of the most common devices, including smartphones, computers, tablets, and home media centers. We analyze 123 real-life multi-device use cases and identify the main usage patterns, including Sequential Use, Resource Lending, Related Parallel Use, and Unrelated Parallel Use. We discuss the practical challenges of using several information devices together. Finally, we identify three levels of decisions that determine which devices are used in a particular situation, including acquiring, making available, and selecting the devices for use.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3903–3912},
numpages = {10},
keywords = {user study, tablets, smartphones, multi-device, mobile use, information devices, device ecologies},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2702613.2732840,
author = {Pelletier, Serge and Suss, Joel and Vachon, Francois and Tremblay, Sebastien},
title = {Atypical Visual Display for Monitoring Multiple CCTV Feeds},
year = {2015},
isbn = {9781450331463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702613.2732840},
doi = {10.1145/2702613.2732840},
abstract = {Despite advances in surveillance technologies, security and command and control (C2) centers still rely strongly on human operators to detect critical events. Human factors-such as cognitive workload and limited attentional capacity-have been shown to affect operators' ability to detect critical incidents. The current standard surveillance environment comprises a large screen layout that simultaneously displays multiple camera feeds. Although having access to all sources of information at once seems intuitively appealing, there is ample evidence to suggest that it can, in fact, lead to poor detection performance. We propose a design solution that is based on principles grounded in cognitive psychology and user experience design. One key objective is to test empirically whether an atypical design pattern that is consistent with serial cognitive processes induces better performance than the current standard surveillance environment. Three variations of the alternative display pattern will be tested by comparing their effects on detection performance within a surveillance microworld.},
booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {1145–1150},
numpages = {6},
keywords = {visualization, user experience design, surveillance, serial processing, security, cognitive system engineering, CCTV},
location = {Seoul, Republic of Korea},
series = {CHI EA '15}
}

@inproceedings{10.1145/2212776.2223670,
author = {Hejmady, Prateek and Narayanan, N. Hari},
title = {Multiple visualizations and debugging: how do we co-ordinate these?},
year = {2012},
isbn = {9781450310161},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2212776.2223670},
doi = {10.1145/2212776.2223670},
abstract = {There are many popular Integrated Development Environments (IDE) that provide multiple visualizations and other sophisticated functionalities to facilitate program comprehension and debugging. To better understand the effectiveness and role of multiple visualizations, we conducted a preliminary study of java program debugging with a professional, multi-representation IDE. We found that program code and dynamic representations (dynamic viewer, variable watch and output) attracted the most attention of programmers. Static representations like Unified Modeling Language (UML) Diagrams and Control Structure Diagrams (CSD) saw significantly lesser usage. Interesting eye gaze patterns of programmers were also revealed by the study.},
booktitle = {CHI '12 Extended Abstracts on Human Factors in Computing Systems},
pages = {1547–1552},
numpages = {6},
keywords = {psychology of programming, program debugging, program comprehension, eye-tracking, attention patterns},
location = {Austin, Texas, USA},
series = {CHI EA '12}
}

@inproceedings{10.1145/2702123.2702405,
author = {Pierce, James and Paulos, Eric},
title = {Making Multiple Uses of the Obscura 1C Digital Camera: Reflecting on the Design, Production, Packaging and Distribution of a Counterfunctional Device},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702405},
doi = {10.1145/2702123.2702405},
abstract = {This paper describes and explains details of the design, production and packaging of a counterfunctional device: The Obscura 1C Digital Camera. We further describe a small-scale distribution of Obscura 1C packages into everyday contexts. The paper then reflects on the various types of conceptual, imaginary and firsthand uses made of the Obscura 1C. These include its uses for everyday audiences as a unique camera and as a conceptually usable device. But we also prioritize uses particular to the HCI and design audience. These include using the Obscura 1C to articulate the concepts of inhibitive interfaces, counterfunctionality, and enabling limitations. The Obscura 1C is further used to articulate how abstract ideas can be translated into material forms, to rethink the role of packaging in user studies, and to draw attention to how discursive design objects are packaged and presented.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2103–2112},
numpages = {10},
keywords = {research through design, limitations, design},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.5555/2729485.2729543,
author = {Park, Sanghoo and Kim, Sangmi and Han, Seungmi},
title = {Analysis of multitasking in the context of using multiple mobile devices: a qualitative research},
year = {2014},
isbn = {9788968487521},
publisher = {Hanbit Media, Inc.},
address = {Seoul, KOR},
abstract = {As a mobile device including smartphones has become one of necessities in everyday life, people are enabled to work on any tasks they want at any time. Moreover, due to mobility and advanced computing system in mobile devices, the users have been habituated to multi-tasking on the devices. We conducted a qualitative study in order to explore multitasking behaviors within the context of using multiple mobile devices. With 19 mobile device users, individual in-depth interviews were carried out. The data from the interviews were analyzed based on grounded theory. In conclusion, various factors such as the number and characteristics of devices, relationships between the tasks have influences on multi-tasking behaviors. Implications and limitations of this study were presented.},
booktitle = {Proceedings of HCI Korea},
pages = {404–411},
numpages = {8},
keywords = {user experience, multitasking, mobile devices, internet of things, human-computer interaction, grounded theory},
location = {Seoul, Republic of Korea},
series = {HCIK '15}
}

@inproceedings{10.1145/2556288.2557405,
author = {Lissermann, Roman and Huber, Jochen and Schmitz, Martin and Steimle, J\"{u}rgen and M\"{u}hlh\"{a}user, Max},
title = {Permulin: mixed-focus collaboration on multi-view tabletops},
year = {2014},
isbn = {9781450324731},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2556288.2557405},
doi = {10.1145/2556288.2557405},
abstract = {We contribute Permulin, an integrated set of interaction and visualization techniques for multi-view tabletops to support co-located collaboration across a wide variety of collaborative coupling styles. These techniques (1) provide support both for group work and for individual work, as well as for the transitions in-between, (2) contribute sharing and peeking techniques to support mutual awareness and group coordination during phases of individual work, (3) reduce interference during group work on a group view, and (4) directly integrate with conventional multi-touch input. We illustrate our techniques in a proof-of-concept implementation with the two example applications of map navigation and photo collages. Results from two user studies demonstrate that Permulin supports fluent transitions between individual and group work and exhibits unique awareness properties that allow participants to be highly aware of each other during tightly coupled collaboration, while being able to unobtrusively perform individual work during loosely coupled collaboration.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3191–3200},
numpages = {10},
keywords = {tabletop, personal input, multi-view, multi touch, mixed-focus collaboration, collaborative coupling styles},
location = {Toronto, Ontario, Canada},
series = {CHI '14}
}

@inproceedings{10.1145/2525194.2525208,
author = {Davis, Richard C. and Steppe, Kevin and Guan, Mengyuan and Khoo, Jing Ting and Zhang, Rui and Koh, Quee Boon},
title = {Flexible grouping and multiple centers for preserving simplicity and flexibility in animation sketches},
year = {2013},
isbn = {9781450322539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2525194.2525208},
doi = {10.1145/2525194.2525208},
abstract = {Animation sketching tools have been shown to make creating animations fast and easy, but editing an animation can make it more complex and harder to modify. To preserve simplicity and flexibility while editing animations, we explored the use of flexible grouping structure and multiple centers for rotation and scaling. We built a modified version of the K-Sketch animation sketching system, which allows grouping structure and center of rotation and scaling to change over time. The modified K-Sketch preserves simplicity when centers change by automatically converting existing motions about the old center to motions about the new center. We evaluated our method by examining traditional and novel grouping methods and center management methods under difficult editing scenarios. We then built video prototypes of these scenarios and gathered feedback from animators.},
booktitle = {Proceedings of the 11th Asia Pacific Conference on Computer Human Interaction},
pages = {73–82},
numpages = {10},
keywords = {animation, iinformal interfaces, pen-based user interfaces, sketching},
location = {Bangalore, India},
series = {APCHI '13}
}

@inproceedings{10.1145/2470654.2481375,
author = {Wang, Yiran and Echenique, Andy and Shelton, Martin and Mark, Gloria},
title = {A comparative evaluation of multiple chat stream interfaces for information-intensive environments},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481375},
doi = {10.1145/2470654.2481375},
abstract = {For information workers who monitor numerous constantly updating data streams, conserving cognitive resources is crucial. This study evaluated how an interface affects information workers' ability to grasp critical information from multiple text-based chat streams under time pressure. We designed and built a working prototype that displays ten chat streams simultaneously in standard chat windows (ST) and ticker tapes (TT). We conducted a lab experiment to evaluate differences in how these two interfaces support signal and context detection. We found that with ST, participants detected significantly more target words (SAT words) with rarer frequency and significantly more context information (disaster facts) than with TT. Our results show that while TT is potentially better for overview scanning of multiple streams, ST is likely to be better for multi-tasking. Our study informs the design of future multi-chat systems so that large amounts of information can be easier to detect and process.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2717–2720},
numpages = {4},
keywords = {monitoring multiple text-based streams, interface evaluation, information workers, empirical study},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2481297,
author = {Xu, Wenchang and Yu, Chun and Zhao, Songmin and Liu, Jie and Shi, Yuanchun},
title = {Facilitating parallel web browsing through multiple-page view},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2481297},
doi = {10.1145/2470654.2481297},
abstract = {Parallel web browsing describes the behavior where users visit web pages in multiple concurrent threads. Qualitative studies have observed this activity being performed with multiple browser windows or tabs. However, these solutions are not satisfying since a large amount of time is wasted on switch among windows and tabs. In this paper, we propose the multiple-page view to facilitate parallel web browsing. Specifically, we provide users with the experience of visiting multiple web pages in one browser window and tab with extensions of prevalent desktop web browsers. Through user study and survey, we found that 2-4 pages within the window size were preferred for multiple-page view in spite of the diverse screen sizes and resolutions. Analytical results of logs from the user study also showed an improvement of 26.3% in users' efficiency of performing parallel web browsing tasks, compared to traditional browsing with multiple windows or tabs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2167–2170},
numpages = {4},
keywords = {user study, parallel web browsing, multiple-page view},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466443,
author = {Fuchs, Johannes and Fischer, Fabian and Mansmann, Florian and Bertini, Enrico and Isenberg, Petra},
title = {Evaluation of alternative glyph designs for time series data in a small multiple setting},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466443},
doi = {10.1145/2470654.2466443},
abstract = {We present the results of a controlled experiment to investigate the performance of different temporal glyph designs in a small multiple setting. Analyzing many time series at once is a common yet difficult task in many domains, for example in network monitoring. Several visualization techniques have, thus, been proposed in the literature. Among these, iconic displays or glyphs are an appropriate choice because of their expressiveness and effective use of screen space. Through a controlled experiment, we compare the performance of four glyphs that use different combinations of visual variables to encode two properties of temporal data: a) the position of a data point in time and b) the quantitative value of this data point. Our results show that depending on tasks and data density, the chosen glyphs performed differently. Line Glyphs are generally a good choice for peak and trend detection tasks but radial encodings are more effective for reading values at specific temporal locations. From our qualitative analysis we also contribute implications for designing temporal glyphs for small multiple settings.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3237–3246},
numpages = {10},
keywords = {time series, small multiples, information visualization, glyphs, evaluation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/3313831.3376809,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L.},
title = {Trackly: A Customisable and Pictorial Self-Tracking App to Support Agency in Multiple Sclerosis Self-Care},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376809},
doi = {10.1145/3313831.3376809},
abstract = {Self-tracking is an important part of self-care. However, predefined self-tracking approaches can impede people's agency in managing their health. We investigated a customisable and pictorial self-tracking approach in multiple sclerosis self-management by implementing and conducting a field study of Trackly: a prototype app that supports people in defining and colouring pictorial trackers, such as body shapes. We found that participants utilised the elements of Trackly designed to support agentive behaviour: they defined personally meaningful tracking parameters in their own words, and particularly valued being able to flexibly colour in and make sense of their pictorial trackers. Having been able to support their individual self-care intentions with Trackly, participants reported a spectrum of interrelated experiences of agency, including a sense of ownership, identity, self-awareness, mindfulness, and control. Our findings demonstrate the importance of supporting people's individual needs and creative capacities to foster mindful and personally meaningful engagement with health and wellbeing data.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {agency, bullet journaling, customisation, customization, mindfulness, mood tracking, perceived control, self-awareness, self-reflection, self-tracking, symptom monitoring},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/1979742.1979711,
author = {Miller, Gregor and Fels, Sidney and Al Hajri, Abir and Ilich, Michael and Foley-Fisher, Zoltan and Fernandez, Manuel and Jang, Daesik},
title = {MediaDiver: viewing and annotating multi-view video},
year = {2011},
isbn = {9781450302685},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1979742.1979711},
doi = {10.1145/1979742.1979711},
abstract = {We propose to bring our novel rich media interface called MediaDiver demonstrating our new interaction techniques for viewing and annotating multiple view video. The demonstration allows attendees to experience novel moving target selection methods (called Hold and Chase), new multi-view selection techniques, automated quality of view analysis to switch viewpoints to follow targets, integrated annotation methods for viewing or authoring meta-content and advanced context sensitive transport and timeline functions. As users have become increasingly sophisticated when managing navigation and viewing of hyper-documents, they transfer their expectations to new media. Our proposal is a demonstration of the technology required to meet these expectations for video. Thus users will be able to directly click on objects in the video to link to more information or other video, easily change camera views and mark-up the video with their own content. The applications of this technology stretch from home video management to broadcast quality media production, which may be consumed on both desktop and mobile platforms.},
booktitle = {CHI '11 Extended Abstracts on Human Factors in Computing Systems},
pages = {1141–1146},
numpages = {6},
keywords = {video annotation, rich media viewing, multi-view interaction},
location = {Vancouver, BC, Canada},
series = {CHI EA '11}
}

@inproceedings{10.1145/1520340.1520500,
author = {Kato, Jun and Sakamoto, Daisuke and Inami, Masahiko and Igarashi, Takeo},
title = {Multi-touch interface for controlling multiple mobile robots},
year = {2009},
isbn = {9781605582474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1520340.1520500},
doi = {10.1145/1520340.1520500},
abstract = {We must give some form of a command to robots in order to have the robots do a complex task. An initial instruction is required even if they do their tasks autonomously. We therefore need interfaces for the operation and teaching of robots. Natural languages, joysticks, and other pointing devices are currently used for this purpose. These interfaces, however, have difficulty in operating multiple robots simultaneously. We developed a multi-touch interface with a top-down view from a ceiling camera for controlling multiple mobile robots. The user specifies a vector field followed by all robots on the view. This paper describes the user interface and its implementation, and future work of the project.},
booktitle = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},
pages = {3443–3448},
numpages = {6},
keywords = {multiple-robot operation, multi-touch interface, human robot interaction, home robot, entertainment robot},
location = {Boston, MA, USA},
series = {CHI EA '09}
}

@inproceedings{10.1145/2207676.2208736,
author = {Hutchings, Dugald},
title = {An investigation of Fitts' law in a multiple-display environment},
year = {2012},
isbn = {9781450310154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2207676.2208736},
doi = {10.1145/2207676.2208736},
abstract = {We describe the design and analysis of a Fitts' law experiment, conducted in a multiple-display environment (MDE), in which the physical gap between displays and the proximity of targets to the gap systematically varied. Participants achieved decreasing throughput values (a combined measure of movement time and accuracy in a target acquisition task) under increasing gap sizes. Participants likewise performed relatively poorly in tasks involving monitor crossing over all gap conditions, especially so when motion either originates or terminates very close to the gap. Both results could be considered surprising since in either case, the amount of mouse movement needed to successfully execute the task does not change based on physical gap size or a target's proximity to the edge. Fitts' law may underestimate the difficulty of movement tasks in MDEs.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3181–3184},
numpages = {4},
keywords = {throughput, multiple-display environment, fitts' law},
location = {Austin, Texas, USA},
series = {CHI '12}
}

@inproceedings{10.1145/3290605.3300629,
author = {Doyle, Julie and Murphy, Emma and Kuiper, Janneke and Smith, Suzanne and Hannigan, Caoimhe and Jacobs, An and Dinsmore, John},
title = {Managing Multimorbidity: Identifying Design Requirements for a Digital Self-Management Tool to Support Older Adults with Multiple Chronic Conditions},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300629},
doi = {10.1145/3290605.3300629},
abstract = {Older adults with multiple chronic conditions (multimorbidity) face complex self-management routines, including symptom monitoring, managing multiple medications, coordinating healthcare visits, communicating with multiple healthcare providers and processing and managing potentially conflicting advice on conditions. While much research exists on single disease management, little, if any research has explored the topic of technology to support those with multimorbidity, particularly older adults, to self-manage with support from a care network. This paper describes a large qualitative study with 125 participants, including older adults with multimorbidity and those who care for them, across two European countries. Key findings related to the: impact of multimorbidity, complexities involved in self-management, motivators and barriers to self-management, sources of support and poor communication as a barrier to care coordination. We present important concepts and design features for a digital health system that aim to address requirements derived from this study.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {self-management, older adults, multimorbidity, digital health},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300792,
author = {Brudy, Frederik and Holz, Christian and R\"{a}dle, Roman and Wu, Chi-Jui and Houben, Steven and Klokmose, Clemens Nylandsted and Marquardt, Nicolai},
title = {Cross-Device Taxonomy: Survey, Opportunities and Challenges of Interactions Spanning Across Multiple Devices},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300792},
doi = {10.1145/3290605.3300792},
abstract = {Designing interfaces or applications that move beyond the bounds of a single device screen enables new ways to engage with digital content. Research addressing the opportunities and challenges of interactions with multiple devices in concert is of continued focus in HCI research. To inform the future research agenda of this field, we contribute an analysis and taxonomy of a corpus of 510 papers in the cross-device computing domain. For both new and experienced researchers in the field we provide: an overview, historic trends and unified terminology of cross-device research; discussion of major and under-explored application areas; mapping of enabling technologies; synthesis of key interaction techniques spanning across multiple devices; and review of common evaluation strategies. We close with a discussion of open issues. Our taxonomy aims to create a unified terminology and common understanding for researchers in order to facilitate and stimulate future cross-device research.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–28},
numpages = {28},
keywords = {taxonomy, survey, multi-device, distributed user interfaces, cross-surface, cross-device interaction, cross-device computing},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3290605.3300565,
author = {Marsden, Nicola and Pr\"{o}bster, Monika},
title = {Personas and Identity: Looking at Multiple Identities to Inform the Construction of Personas},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300565},
doi = {10.1145/3290605.3300565},
abstract = {Personas are valuable tools to help designers get to know their users and adopt their perspectives. Yet people are complex and multiple identities have to be considered in their interplay to account for a comprehensive representation otherwise, personas might be superficial and prone to activate stereotypes. Therefore, the way users' identities are presented in a limited set of personas is crucial to account for diversity and highlight facets which otherwise would go unnoticed. In this paper, we introduce an approach to the development of personas informed by social identity theory. The effectiveness of this approach is investigated in a qualitative study in the context of the design process for an e-learning platform for women in tech. The results suggest that considering multiple identities in the construction of personas adds value when designing technologies.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {social identity, qualitative study, personas, gender, co-design},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/1978942.1979433,
author = {Hutama, William and Song, Peng and Fu, Chi-Wing and Goh, Wooi Boon},
title = {Distinguishing multiple smart-phone interactions on a multi-touch wall display using tilt correlation},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979433},
doi = {10.1145/1978942.1979433},
abstract = {While very large collaborative surfaces are already being widely employed to facilitate concurrent interactions with multiple users, they involve no personalization in the touch interactions. Augmenting them to identify the touch interactions with multiple smart-phones can enable interesting co-located communal applications with context-based personalized interactions and information exchange amongst users' portable devices and the shared wall display. This paper proposes a novel matching technique, called tilt correlation, which employs the built-in tilt sensor to identify smart-phones that make concurrent two-point contacts on a common multi-touch wall display. Experimental investigations suggest that the resultant error rate is relatively low; in addition, we also propose a quantitative measure, called the Bourne Identity Index to allow application designers to determine the reliability of each device identification.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3315–3318},
numpages = {4},
keywords = {personal handheld device, multi-touch interaction, collaborative interactions},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1978942.1979067,
author = {Quinn, Philip and Cockburn, Andy and R\"{a}ih\"{a}, Kari-Jouko and Delamarche, J\'{e}r\^{o}me},
title = {On the costs of multiple trajectory pointing methods},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979067},
doi = {10.1145/1978942.1979067},
abstract = {Several enhanced pointing techniques aim to reduce the Fitts' law targeting distance by providing multiple target trajectories in the hope that a shorter path is available. However, these techniques introduce a search or decision component to pointing users must examine the alternatives available and decide upon the trajectory to use. We analyse these difficulties, present a methodology for examining them as well as other behaviour issues, and report empirical results of performance with pointer wrapping and Ninja cursors. Results show that offering multiple trajectories incurs a significant search or decision cost, and that users are therefore poor at capitalising on the theoretical benefits of reduced target distance.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {859–862},
numpages = {4},
keywords = {wrapping cursors, search/decision, pointing, ninja cursors, multiple trajectories, fitt's law},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/1240624.1240658,
author = {Hutchings, Dugald Ralph and Stasko, John},
title = {Consistency, multiple monitors, and multiple windows},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240658},
doi = {10.1145/1240624.1240658},
abstract = {We present an evaluation of mudibo, a prototype system for determining the position of dialog boxes in a multiple-monitor system. The analysis shows that, when compared to a standard approach, mudibo offered a 24% decrease in time needed to begin interaction in a dialog box. Analysis of participant behavior in the evaluation provides insight into the way users perceive and act in multiple-monitor environments. Specifically, the notion of consistency changes for multiple-monitor systems and the prospect of adaptive algorithms becomes further complicated and intricate, especially for window management.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {211–214},
numpages = {4},
keywords = {window management, multiple monitors, consistency},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1753326.1753531,
author = {Amershi, Saleema and Fogarty, James and Kapoor, Ashish and Tan, Desney},
title = {Examining multiple potential models in end-user interactive concept learning},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753326.1753531},
doi = {10.1145/1753326.1753531},
abstract = {End-user interactive concept learning is a technique for interacting with large unstructured datasets, requiring insights from both human-computer interaction and machine learning. This note re-examines an assumption implicit in prior interactive machine learning research, that interaction should focus on the question "what class is this object?". We broaden interaction to include examination of multiple potential models while training a machine learning system. We evaluate this approach and find that people naturally adopt revision in the interactive machine learning process and that this improves the quality of their resulting models for difficult concepts.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1357–1360},
numpages = {4},
keywords = {end-user interactive concept learning},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}

@inproceedings{10.1145/3173574.3173626,
author = {Sannon, Shruti and Bazarova, Natalya N. and Cosley, Dan},
title = {Privacy Lies: Understanding How, When, and Why People Lie to Protect Their Privacy in Multiple Online Contexts},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173626},
doi = {10.1145/3173574.3173626},
abstract = {In this paper, we study online privacy lies: lies primarily aimed at protecting privacy. Going beyond privacy lenses that focus on privacy concerns or cost/benefit analyses, we explore how contextual factors, motivations, and individual-level characteristics affect lying behavior through a 356-person survey. We find that statistical models to predict privacy lies that include attitudes about lying, use of other privacy-protective behaviors (PPBs), and perceived control over information improve on models based solely on self-expressed privacy concerns. Based on a thematic analysis of open-ended responses, we find that the decision to tell privacy lies stems from a range of concerns, serves multiple privacy goals, and is influenced by the context of the interaction and attitudes about the morality and necessity of lying. Together, our results point to the need for conceptualizations of privacy lies-and PPBs more broadly-that account for multiple goals, perceived control over data, contextual factors, and attitudes about PPBs.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {privacy-protective behaviors, privacy, deception, computer-mediated communication},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/1518701.1518837,
author = {Everitt, Katherine M. and Bragin, Tanya and Fogarty, James and Kohno, Tadayoshi},
title = {A comprehensive study of frequency, interference, and training of multiple graphical passwords},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518837},
doi = {10.1145/1518701.1518837},
abstract = {Graphical password systems have received significant attention as one potential solution to the need for more usable authentication, but nearly all prior work makes the unrealistic assumption of studying a single password. This paper presents the first study of multiple graphical passwords to systematically examine frequency of access to a graphical password, interference resulting from interleaving access to multiple graphical passwords, and patterns of access while training multiple graphical passwords. We find that all of these factors significantly impact the ease of authenticating using multiple facial graphical passwords. For example, participants who accessed four different graphical passwords per week were ten times more likely to completely fail to authenticate than participants who accessed a single password once per week. Our results underscore the need for more realistic evaluations of the use of multiple graphical passwords, have a number of implications for the adoption of graphical password systems, and provide a new basis for comparing proposed graphical password systems.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {889–898},
numpages = {10},
keywords = {usable security, graphical passwords, authentication},
location = {Boston, MA, USA},
series = {CHI '09}
}

@inproceedings{10.1145/1520340.1520669,
author = {Kadaba, Nivedita R. and Yang, Xing-Dong and Irani, Pourang P.},
title = {Facilitating multiple target tracking using semantic depth of field (SDOF)},
year = {2009},
isbn = {9781605582474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1520340.1520669},
doi = {10.1145/1520340.1520669},
abstract = {Users of radar control systems and monitoring applications have to constantly extract essential information from dynamic scenes. In these environments a critical and elemental task consists of tracking multiple targets that are moving simultaneously. However, focusing on multiple moving targets is not trivial as it is very easy to lose continuity, particularly when the objects are situated within a very dense or cluttered background. While focus+context displays have been developed to improve users' ability to attend to important visual information, such techniques have not been applied to the visualization of moving objects. In this paper we evaluate the effectiveness of a focus+context technique, referred to as Semantic Depth of Field (SDOF), to the task of facilitating multiple target tracking. Results of our studies show an inclination for better performance with SDOF techniques, especially in low contrast scenarios.},
booktitle = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},
pages = {4375–4380},
numpages = {6},
keywords = {visualization, visual displays, target tracking, semantic depth of field, preattentive cues, moving targets, blurring},
location = {Boston, MA, USA},
series = {CHI EA '09}
}

@inproceedings{10.1145/1520340.1520638,
author = {Gunn, Tyler J. and Zhang, Hong and Mak, Ed and Irani, Pourang},
title = {An evaluation of one-handed techniques for multiple-target selection},
year = {2009},
isbn = {9781605582474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1520340.1520638},
doi = {10.1145/1520340.1520638},
abstract = {Recent research has revealed that a large population of mobile users usually use one hand when interacting with mobile devices. However, very few techniques have been developed to support multiple-target selection. In this paper, we introduce Burst and ZoomTap, two techniques that aim to facilitate accurate and fast multiple-target acquisition with one-handed thumb operation on touch-based mobile devices. We compare our two techniques to Shift in a controlled experiment. The results show that for multiple-target selection, Burst and ZoomTap can outperform Shift; also according to the questionnaire, participants prefer Burst and ZoomTap to Shift.},
booktitle = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},
pages = {4189–4194},
numpages = {6},
keywords = {touchscreens, one-handed interaction, multiple target selection, mobile devices, input technique},
location = {Boston, MA, USA},
series = {CHI EA '09}
}

@inproceedings{10.1145/3173574.3173611,
author = {Zhang, Jiawei and Surakitbanharn, Chittayong and Elmqvist, Niklas and Maciejewski, Ross and Qian, Zhenyu and Ebert, David S.},
title = {TopoText: Context-Preserving Text Data Exploration Across Multiple Spatial Scales},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173611},
doi = {10.1145/3173574.3173611},
abstract = {TopoText is a context-preserving technique for visualizing text data for multi-scale spatial aggregates to gain insight into spatial phenomena. Conventional exploration requires users to navigate across multiple scales but only presents the information related to the current scale. This limitation potentially adds more steps of interaction and cognitive overload to the users. TopoText renders multi-scale aggregates into a single visual display combining novel text-based encoding and layout methods that draw labels along the boundary or filled within the aggregates. The text itself not only summarizes the semantics at each individual scale, but also indicates the spatial coverage of the aggregates and their underlying hierarchical relationships. We validate TopoText with both a user study as well as several application examples.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {typographic map, text visualization, multi-scale analysis, geospatial visualization, context preservation},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@inproceedings{10.1145/3025453.3025869,
author = {Ayobi, Amid and Marshall, Paul and Cox, Anna L. and Chen, Yunan},
title = {Quantifying the Body and Caring for the Mind: Self-Tracking in Multiple Sclerosis},
year = {2017},
isbn = {9781450346559},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3025453.3025869},
doi = {10.1145/3025453.3025869},
abstract = {Consumer health technologies have an enormous potential to transform the self-management of chronic conditions. However, it is unclear how individuals use self-tracking technologies to manage them. This in-depth interview study explores self-tracking practices in multiple sclerosis (MS), a complex neurological disease that causes physical, cognitive, and psychological symptoms. Our findings illustrate that when faced the unpredictable and degenerative nature of MS, individuals regained a sense of control by intertwining self-care practices with different self-tracking technologies. They engaged in disease monitoring, fitness tracking, and life journaling to quantify the body and care for the mind. We focus attention on the role of emotional wellbeing and the experience of control in self-tracking and managing MS. Finally, we discuss in which ways self-tracking technologies could support the experiential nature of control and foster mindful experiences rather than focusing only on tracking primary disease indicators.},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
pages = {6889–6901},
numpages = {13},
keywords = {self-tracking, self-care technologies, personal informatics, perceived control, multiple sclerosis, chronic conditions},
location = {Denver, Colorado, USA},
series = {CHI '17}
}

@inproceedings{10.1145/1240624.1240864,
author = {Pawar, Udai Singh and Pal, Joyojeet and Gupta, Rahul and Toyama, Kentaro},
title = {Multiple mice for retention tasks in disadvantaged schools},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240864},
doi = {10.1145/1240624.1240864},
abstract = {This study evaluates single-mouse and multiple-mice configurations for computer-aided learning in schools where access to computers is limited due to resource constraints. Multimouse, a single display groupware solution, developed to allow multiple mice to be used simultaneously on a single PC, is compared with single-user-single-mouse and multiple-user-single-mouse scenarios. Multimouse itself is trialed with two unique interaction designs -- one where competitive interaction among students is encouraged, and another where more collaborative interaction is expected. Experiments were conducted with 238 schoolchildren from underprivileged households in rural India on an English vocabulary retention task. On the whole, Multimouse configurations (five users each) were found to be at par with single-user scenarios in terms of actual words learned by students. This suggests that the value of a PC can be inexpensively multiplied by employing a multi-input shared-use design. Gender effects were found, where boys show significant differences in learning depending on interaction modality, whereas girls learned at similar rates across configurations. In addition, a comparison of the two Multimouse modes -- collaborative and competitive -- showed the striking difference in learning outcomes and user behavior that is possible due to even slight variations in interaction designs for multiple-mice.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1581–1590},
numpages = {10},
keywords = {single display groupware, shared computers, multiple mice, education, developing nations},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240866.1240874,
author = {Galicia, Leonardo},
title = {Supporting proactive planning of multiple activities},
year = {2007},
isbn = {9781595936424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240866.1240874},
doi = {10.1145/1240866.1240874},
abstract = {Many studies have shown that the nature of information work demands constant switching among multiple activities. This doctoral dissertation aims at expanding the understanding of the process and strategies involved in personal activity management (PAM), including planning, managing and organizing multiples activities and their resources, with the goal of designing, implementing and testing appropriate supportive information technology.},
booktitle = {CHI '07 Extended Abstracts on Human Factors in Computing Systems},
pages = {1649–1652},
numpages = {4},
keywords = {planning activities, personal activity management, information technology},
location = {San Jose, CA, USA},
series = {CHI EA '07}
}

@inproceedings{10.1145/1240624.1240668,
author = {Wong, Jeffrey and Oh, Lui Min and Ou, Jiazhi and Ros\'{e}, Carolyn P. and Yang, Jie and Fussell, Susan R.},
title = {Sharing a single expert among multiple partners},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240668},
doi = {10.1145/1240624.1240668},
abstract = {Expertise to assist people on complex tasks is often in short supply. One solution to this problem is to design systems that allow remote experts to help multiple people in simultaneously. As a first step towards building such a system, we studied experts' attention and communication as they assisted two novices at the same time in a co-located setting. We compared simultaneous instruction when the novices are being instructed to do the same task or different tasks. Using machine learning, we attempted to identify speech markers of upcoming attention shifts that could serve as input to a remote assistance system.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {261–270},
numpages = {10},
keywords = {video-mediated communication, remote expertise, remote collaborative physical tasks, multi-tasking, multi-party conversation, grounding, focus-of-attention},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/2858036.2858125,
author = {Chen, Ke-Yu and Patel, Shwetak N. and Keller, Sean},
title = {Finexus: Tracking Precise Motions of Multiple Fingertips Using Magnetic Sensing},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858125},
doi = {10.1145/2858036.2858125},
abstract = {With the resurgence of head-mounted displays for virtual reality, users need new input devices that can accurately track their hands and fingers in motion. We introduce Finexus, a multipoint tracking system using magnetic field sensing. By instrumenting the fingertips with electromagnets, the system can track fine fingertip movements in real time using only four magnetic sensors. To keep the system robust to noise, we operate each electromagnet at a different frequency and leverage bandpass filters to distinguish signals attributed to individual sensing points. We develop a novel algorithm to efficiently calculate the 3D positions of multiple electromagnets from corresponding field strengths. In our evaluation, we report an average accuracy of 1.33 mm, as compared to results from an optical tracker. Our real-time implementation shows Finexus is applicable to a wide variety of human input tasks, such as writing in the air.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {1504–1514},
numpages = {11},
keywords = {wearable, tracking, real-time, magnetic field, localization, fingertips, electromagnet, 3D space},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/1125451.1125496,
author = {Lindt, Irma and Ohlenburg, Jan and Pankoke-Babatz, Uta and Prinz, Wolfgang and Ghellal, Sabiha},
title = {Combining multiple gaming interfaces in epidemic menace},
year = {2006},
isbn = {1595932984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1125451.1125496},
doi = {10.1145/1125451.1125496},
abstract = {This paper presents the multiple gaming interfaces of the crossmedia game Epidemic Menace, including a game board station, a mobile assistant and a mobile Augmented Reality (AR) system. Each gaming interface offers different functionality within the game play. We explain the interfaces and describe early results of an ethnographic observation showing how the different gaming interfaces were used by the players to observe, collaborate and interact within the game.},
booktitle = {CHI '06 Extended Abstracts on Human Factors in Computing Systems},
pages = {213–218},
numpages = {6},
keywords = {user interfaces, pervasive gaming, evaluation, design, crossmedia, computer games, augmented reality},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI EA '06}
}

@inproceedings{10.1145/2858036.2858358,
author = {Kim, Ju-Whan and Kim, Han-Jong and Nam, Tek-Jin},
title = {M.Gesture: An Acceleration-Based Gesture Authoring System on Multiple Handheld and Wearable Devices},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858358},
doi = {10.1145/2858036.2858358},
abstract = {Gesture-based interaction is still underutilized in the mobile context despite the large amount of attention it has been given. Using accelerometers that are widely available in mobile devices, we developed M.Gesture, a software system that supports accelerometer-based gesture authoring on single or multiple mobile devices. The development was based on a formative study that showed users' preferences for subtle, simple motions and synchronized, multi-device gestures. M.Gesture adopts an acceleration data space and interface components based on mass-spring analogy and combines the strengths of both demonstration-based and declarative approaches. Also, gesture declaration is done by specifying a mass-spring trajectory with planes in the acceleration space. For iterative gesture modification, multi-level feedbacks are provided as well. The results of evaluative studies have shown good usability and higher recognition performance than that of dynamic time warping for simple gesture authoring. Later, we discuss the benefits of applying a physical metaphor and hybrid approach.},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {2307–2318},
numpages = {12},
keywords = {multi-device gesture, mass-spring visualization, hybrid approach, gesture authoring, acceleration space},
location = {San Jose, California, USA},
series = {CHI '16}
}

@inproceedings{10.1145/2851581.2892286,
author = {Pittman, Corey and Wisniewski, Pamela and Brooks, Conner and LaViola, Joseph J.},
title = {Multiwave: Doppler Effect Based Gesture Recognition in Multiple Dimensions},
year = {2016},
isbn = {9781450340823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2851581.2892286},
doi = {10.1145/2851581.2892286},
abstract = {We constructed an acoustic, gesture-based recognition system called Multiwave, which leverages the Doppler Effect to translate multidimensional movements into user interface commands. Our system only requires the use of two speakers and a microphone to be operational. Since these components are already built in to most end user systems, our design makes gesture-based input more accessible to a wider range of end users. By generating a known high frequency tone from multiple speakers and detecting movement using changes in the sound waves, we are able to calculate a Euclidean representation of hand velocity that is then used for more natural gesture recognition and thus, more meaningful interaction mappings. We present the results of a user study of Multiwave to evaluate recognition rates for different gestures and report accuracy rates comparable to or better than the current state of the art. We also report subjective user feedback and some lessons learned from our system that provide additional insight for future applications of multidimensional gesture recognition.},
booktitle = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {1729–1736},
numpages = {8},
keywords = {user studies, gesture recognition, doppler effect, 3D interaction},
location = {San Jose, California, USA},
series = {CHI EA '16}
}

@inproceedings{10.1145/1056808.1057048,
author = {Yost, Beth and North, Chris},
title = {Single complex glyphs versus multiple simple glyphs},
year = {2005},
isbn = {1595930027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1056808.1057048},
doi = {10.1145/1056808.1057048},
abstract = {Designers of information visualization systems have the choice to present information in a single integrated view or in multiple views. In practice, there is a continuum between the two strategies and designers must decide how much of each strategy to apply. Although high-level design guidelines (heuristics) are available, there are few low-level perceptual design guidelines for making this decision. We performed a controlled experiment with one, two, and four views to evaluate the strengths and weaknesses of these strategies on target detection and trend finding tasks in the context of multidimensional glyphs overlaid onto geographic maps. Results from the target detection tasks suggest that visual encoding is a more important factor when detecting a single attribute than the number of views. Additionally, for detecting two attributes, the trend indicates that reusing the most perceptually salient visual feature in multiple views provides faster performance than an integrated view that must map one of the attributes to a less salient feature.},
booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
pages = {1889–1892},
numpages = {4},
keywords = {multiple views, information visualization, evaluation},
location = {Portland, OR, USA},
series = {CHI EA '05}
}

@inproceedings{10.1145/1054972.1055029,
author = {Tollinger, Irene and Lewis, Richard L. and McCurdy, Michael and Tollinger, Preston and Vera, Alonso and Howes, Andrew and Pelton, Laura},
title = {Supporting efficient development of cognitive models at multiple skill levels: exploring recent advances in constraint-based modeling},
year = {2005},
isbn = {1581139985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1054972.1055029},
doi = {10.1145/1054972.1055029},
abstract = {This paper presents X-PRT, a new cognitive modeling tool supporting activities ranging from interface design to basic cognitive research. X-PRT provides a graphical model development environment for the CORE constraint-based cognitive modeling engine [7,13,21]. X-PRT comprises a novel feature set: (a) it supports the automatic generation of predictive models at multiple skill levels from a single task-specification, (b) it supports a comprehensive set of modeling activities, and (c) it supports compositional reuse of existing cognitive/perceptual/motor skills by transforming high-level, hierarchical task descriptions into detailed performance predictions. Task hierarchies play a central role in X-PRT, serving as the organizing construct for task knowledge, the locus for compositionality, and the cognitive structures over which the learning theory is predicated. Empirical evidence supports the role of task hierarchies in routine skill acquisition.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {411–420},
numpages = {10},
keywords = {user modeling, tools for usability evaluationm},
location = {Portland, Oregon, USA},
series = {CHI '05}
}

@inproceedings{10.1145/1056808.1056873,
author = {Ashdown, Mark and Oka, Kenji and Sato, Yoichi},
title = {Combining head tracking and mouse input for a GUI on multiple monitors},
year = {2005},
isbn = {1595930027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1056808.1056873},
doi = {10.1145/1056808.1056873},
abstract = {The use of multiple LCD monitors is becoming popular as prices are reduced, but this creates problems for window management and switching between applications. For a single monitor, eye tracking can be combined with the mouse to reduce the amount of mouse movement, but with several monitors the head is moved through a large range of positions and angles which makes eye tracking difficult. We thus use head tracking to switch the mouse pointer between monitors and use the mouse to move within each monitor. In our experiment users required significantly less mouse movement with the tracking system, and preferred using it, although task time actually increased. A graphical prompt (flashing star) prevented the user losing the pointer when switching monitors. We present discussions on our results and ideas for further developments.},
booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
pages = {1188–1191},
numpages = {4},
keywords = {multiple monitors, head tracking, gaze-contingent display, attentive user interface},
location = {Portland, OR, USA},
series = {CHI EA '05}
}

@inproceedings{10.1145/1518701.1518772,
author = {Park, Souneil and Kang, Seungwoo and Chung, Sangyoung and Song, Junehwa},
title = {NewsCube: delivering multiple aspects of news to mitigate media bias},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518772},
doi = {10.1145/1518701.1518772},
abstract = {The bias in the news media is an inherent flaw of the news production process. The resulting bias often causes a sharp increase in political polarization and in the cost of conflict on social issues such as Iraq war. It is very difficult, if not impossible, for readers to have penetrating views on realities against such bias. This paper presents NewsCube, a novel Internet news service aiming at mitigating the effect of media bias. NewsCube automatically creates and promptly provides readers with multiple classified viewpoints on a news event of interest. As such, it effectively helps readers understand a fact from a plural of viewpoints and formulate their own, more balanced viewpoints. While media bias problem has been studied extensively in communications and social sciences, our work is the first to develop a news service as a solution and study its effect. We discuss the effect of the service through various user studies.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {443–452},
numpages = {10},
keywords = {news distribution service, news, media bias, aspect-level browsing},
location = {Boston, MA, USA},
series = {CHI '09}
}

@inproceedings{10.1145/2702123.2702241,
author = {Al-Ameen, Mahdi Nasrullah and Wright, Matthew and Scielzo, Shannon},
title = {Towards Making Random Passwords Memorable: Leveraging Users' Cognitive Ability Through Multiple Cues},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702241},
doi = {10.1145/2702123.2702241},
abstract = {Given the choice, users produce passwords reflecting common strategies and patterns that ease recall but offer uncertain and often weak security. System-assigned passwords provide measurable security but suffer from poor memorability. To address this usability-security tension, we argue that systems should assign random passwords but also help with memorization and recall. We investigate the feasibility of this approach with CuedR, a novel cued-recognition authentication scheme that provides users with multiple cues (visual, verbal, and spatial) and lets them choose the cues that best fit their learning process for later recognition of system-assigned keywords. In our lab study, all 37 of our participants could log in within three attempts one week after registration (mean login time: 38.0 seconds). A pilot study on using multiple CuedR passwords also showed 100% recall within three attempts. Based on our results, we suggest appropriate applications for CuedR, such as financial and e-commerce accounts.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {2315–2324},
numpages = {10},
keywords = {usable security, cued-recognition, authentication},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/985692.985717,
author = {Fussell, Susan R. and Kiesler, Sara and Setlock, Leslie D. and Scupelli, Peter and Weisband, Suzanne},
title = {Effects of instant messaging on the management of multiple project trajectories},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985717},
doi = {10.1145/985692.985717},
abstract = {We present a study of the effects of instant messaging (IM) on individuals' management of work across multiple collaborative projects. Groups of four participants completed four web design tasks. Each participant worked on two tasks, each task with a different partner who was either co-located or remote, connected via IM. In one condition, each participant had one co-located and one remote partner. In a second condition, both partners were remote. We examined communication, division of labor, and task performance as a function of condition. The results indicated that nearly all participants divided their time unequally between projects, but less unequally in the remote/remote condition. In the co-located/remote condition, participants favored the task with the co-located partner. The results show that the effects of IM differ depending on people's multiple tasks are distributed across space. We propose a new IM interface that promotes awareness of multiple collaborators on multiple tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {191–198},
numpages = {8},
keywords = {intellectual teamwork, empirical studies, distributed work, coordination mechanisms, collaborative writing, CSCW},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/2702123.2702386,
author = {Fleck, Rowanne and Cox, Anna L. and Robison, Rosalyn A.V.},
title = {Balancing Boundaries: Using Multiple Devices to Manage Work-Life Balance},
year = {2015},
isbn = {9781450331456},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702123.2702386},
doi = {10.1145/2702123.2702386},
abstract = {Information and communication technologies (ICTs) continue to give us increased flexibility about when and where we choose to work and the freedom to deal with home tasks whilst at work. However more use of ICT for work during non-work time has been linked with negative outcomes including lower work and life satisfaction and increased stress. Previous work has suggested that in order to reduce some of these negative effects, people should adopt technology use strategies that aid separation of their home and work lives. In this paper we report the results of a questionnaire study investigating work-life balance boundary behaviours and technology use. We find that people use multiple devices as a way of creating boundaries between home and work, and the extent to which they do this relates to their boundary behaviour style. These findings have particular relevance given the increasing trend for Bring Your Own Device (BYOD) policies.},
booktitle = {Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems},
pages = {3985–3988},
numpages = {4},
keywords = {technology boundary work, life-work balance, device separation, bring your own device, boundary control},
location = {Seoul, Republic of Korea},
series = {CHI '15}
}

@inproceedings{10.1145/2559206.2581232,
author = {Wozniak, Pawel W. and Schmidt, Benjamin and Lischke, Lars and Franjcic, Zlatko and Yanta\c{c}, Asim Evren and Fjeld, Morten},
title = {MochaTop: building ad-hoc data spaces with multiple devices},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2581232},
doi = {10.1145/2559206.2581232},
abstract = {We present MochaTop-a system using multiple mobile devices that is part of our on-going inquiry into ad-hoc multi-device environments on tabletops. In this progress report, we describe the motivation for designing multi-device, ad-hoc systems for single and multiple users, and explain the design and implementation of our prototype system. We report on preliminary user studies made with focus groups and sandbox explorations of the prototype, with video analysis. By designing new interaction patterns, we focus on investigating if multiple mobile devices can be used to transform everyday settings into new environments for data exploration. Our research indicates that users value the extended interactive space created by multiple mobile devices.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {2329–2334},
numpages = {6},
keywords = {multiple device environments, mobile interaction, data analysis},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@inproceedings{10.1145/2559206.2574770,
author = {Gomes, Antonio and Vertegaal, Roel},
title = {Paperfold: a shape changing mobile device with multiple reconfigurable electrophoretic magnetic display tiles},
year = {2014},
isbn = {9781450324748},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2559206.2574770},
doi = {10.1145/2559206.2574770},
abstract = {We present PaperFold, a novel shape changing mobile device with multiple reconfigurable touch sensitive thin-film electrophoretic magnetic display tiles. PaperFold explores the perceived benefits of having multiple computing devices combined into a single mobile device featuring multiple detachable displays. In PaperFold, each display tile can act independently or as part of a single system. Advantages include better support for performing tasks that traditionally require multiple devices, as well as physical manipulation and sharing of views. Touch and Inertial Measurement Unit (IMU) sensors embedded in each display tile allow users to dynamically manipulate content.},
booktitle = {CHI '14 Extended Abstracts on Human Factors in Computing Systems},
pages = {535–538},
numpages = {4},
keywords = {organic user interfaces, human factors, foldable user interfaces, flexible displays},
location = {Toronto, Ontario, Canada},
series = {CHI EA '14}
}

@inproceedings{10.1145/642611.642620,
author = {Hwang, Faustina and Keates, Simeon and Langdon, Patrick and Clarkson, P. John},
title = {Multiple haptic targets for motion-impaired computer users},
year = {2003},
isbn = {1581136307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/642611.642620},
doi = {10.1145/642611.642620},
abstract = {Although a number of studies have reported that force feedback gravity wells can improve performance in "point-and-click" tasks, there have been few studies addressing issues surrounding the use of gravity wells for multiple on-screen targets. This paper investigates the performance of users, both with and without motion-impairments, in a "point-and-click" task when an undesired haptic distractor is present. The importance of distractor location is studied explicitly. Results showed that gravity wells can still improve times and error rates, even on occasions when the cursor is pulled into a distractor. The greatest improvement is seen for the most impaired users. In addition to traditional measures such as time and errors, performance is studied in terms of measures of cursor movement along a path. Two cursor measures, angular distribution and temporal components, are proposed and their ability to explain performance differences is explored.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {41–48},
numpages = {8},
keywords = {motion-impaired, force feedback, cursor control, Wingman},
location = {Ft. Lauderdale, Florida, USA},
series = {CHI '03}
}

@inproceedings{10.1145/2470654.2466441,
author = {Perin, Charles and Vernier, Fr\'{e}d\'{e}ric and Fekete, Jean-Daniel},
title = {Interactive horizon graphs: improving the compact visualization of multiple time series},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466441},
doi = {10.1145/2470654.2466441},
abstract = {Many approaches have been proposed for the visualization of multiple time series. Two prominent approaches are reduced line charts (RLC), which display small multiples for time series, and the more recent horizon graphs (HG). We propose to unify RLC and HG using a new technique - interactive horizon graphs (IHG) - which uses pan and zoom interaction to increase the number of time series that can be analysed in parallel. In a user study we compared RLC, HG, and IHG across several tasks and numbers of time series, focusing on datasets with both large scale and small scale variations. Our results show that IHG outperform the other two techniques in complex comparison and matching tasks where the number of charts is large. In the hardest task PHG have a significantly higher number of good answers (correctness) than HG (+14%) and RLC (+51%) and a lower error magnitude than HG (-64%) and RLC (-86%).},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {3217–3226},
numpages = {10},
keywords = {visualization, time series, horizon graphs, evaluation},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/2470654.2466235,
author = {Lafreniere, Benjamin and Grossman, Tovi and Fitzmaurice, George},
title = {Community enhanced tutorials: improving tutorials with multiple demonstrations},
year = {2013},
isbn = {9781450318990},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2470654.2466235},
doi = {10.1145/2470654.2466235},
abstract = {Web-based tutorials are a popular help resource for learning how to perform unfamiliar tasks in complex software. However, in their current form, web tutorials are isolated from the applications that they support. In this paper we present FollowUs, a web-tutorial system that integrates a fully-featured application into a web-based tutorial. This novel architecture enables community enhanced tutorials, which continuously improve as more users work with them. FollowUs captures video demonstrations of users as they perform a tutorial. Subsequent users can use the original tutorial, or choose from a library of captured community demonstrations of each tutorial step. We conducted a user study to test the benefits of making multiple demonstrations available to users, and found that users perform significantly better using our system with a library of multiple demonstrations in comparison to its equivalent baseline system with only the original authored content.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1779–1788},
numpages = {10},
keywords = {tutorials, learning, help, community},
location = {Paris, France},
series = {CHI '13}
}

@inproceedings{10.1145/634067.634304,
author = {Boardman, Richard},
title = {Multiple hierarchies in user workspace},
year = {2001},
isbn = {1581133405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/634067.634304},
doi = {10.1145/634067.634304},
abstract = {Desktop workspaces contain many user-defined hierarchies such as the file system, email folders and web bookmark folders. Previous studies have shown that users encounter many overheads in the management and navigation of individual hierarchies. In contrast, this paper presents an exploratory study of how users work with the multiple hierarchies of their workspace.The organisations of three hierarchies (file system, email folders and web bookmark folders) were compared for ten users. The study found that overheads are compounded when working with multiple hierarchies. Improved support is required for managing multiple hierarchies in user workspace. The sharing of organisational information between hierarchies is proposed as one possible approach.},
booktitle = {CHI '01 Extended Abstracts on Human Factors in Computing Systems},
pages = {403–404},
numpages = {2},
keywords = {workspace organisation, multiple hierarchies, desktop},
location = {Seattle, Washington},
series = {CHI EA '01}
}

@inproceedings{10.1145/634067.634188,
author = {North, Chris and Shneiderman, Ben},
title = {Component-based, user-constructed, multiple-view visualization},
year = {2001},
isbn = {1581133405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/634067.634188},
doi = {10.1145/634067.634188},
abstract = {A major hindrance to the usage of information visualization in common tasks is that typically a new visualization interface must be custom programmed to suit each task. This video demonstrates a system and user interface that attempts to solve this problem by enabling end users to construct their own multiple-view visualization interfaces that are appropriate for their tasks and data. Users accomplish this by snapping together component visualizations and specifying tight couplings between them. Then they can use their newly constructed visualization interfaces to perform their tasks.},
booktitle = {CHI '01 Extended Abstracts on Human Factors in Computing Systems},
pages = {201–202},
numpages = {2},
keywords = {user interface, tight coupling, specification, software components, multiple views, information visualization},
location = {Seattle, Washington},
series = {CHI EA '01}
}

@inproceedings{10.1145/2468356.2479628,
author = {Tarun, Aneesh P. and Wang, Peng and Girouard, Audrey and Strohmeier, Paul and Reilly, Derek and Vertegaal, Roel},
title = {PaperTab: an electronic paper computer with multiple large flexible electrophoretic displays},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2479628},
doi = {10.1145/2468356.2479628},
abstract = {We present Papertab, a paper computer with multiple 10.7" functional touch sensitive flexible electrophoretic displays. Papertab merges the benefits of working with electronic documents with the tangibility of paper documents. In Papertab, each document window is represented as a physical, functional, flexible e-paper screen called a displaywindow. Each displaywindow is an Android computer that can show documents at varying resolutions. The location of displaywindows is tracked on the desk using an electro-magnetic tracker. This allows for context-aware operations between displaywindows. Touch and bend sensors in each displaywindow allow users to navigate content.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {3131–3134},
numpages = {4},
keywords = {organic user interfaces, flexible display interfaces},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/633292.633297,
author = {Rekimoto, Jun},
title = {Multiple-computer user interfaces: "beyond the desktop" direct manipulation environments},
year = {2000},
isbn = {1581132484},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/633292.633297},
doi = {10.1145/633292.633297},
abstract = {Graphical user interfaces (GUIs) are mainly designed for a single computer and a set of single input devices. However, when we simultaneously use many and different types of computers and electronic devices, such interfaces would often fail to work. As we can combine several tools to perform a task in the real world, we consider that it should be possible to dynamically combine multiple digital devices. It should also be possible to use "direct manipulation" interfaces that work across the boundary of these devices. We call this concept "multiple-computer user interfaces". This video demonstrates several interaction techniques based on this concept, including Pick-and-Drop, a digital whiteboard system with palmtop computers, and a digital table that can recognize objects placed on it.},
booktitle = {CHI '00 Extended Abstracts on Human Factors in Computing Systems},
pages = {6–7},
numpages = {2},
keywords = {ubiquitous computing, pick-and-drop, multiple-device user interfaces, direct manipulation},
location = {The Hague, The Netherlands},
series = {CHI EA '00}
}

@inproceedings{10.1145/1978942.1979359,
author = {Dow, Steven and Fortuna, Julie and Schwartz, Dan and Altringer, Beth and Schwartz, Daniel and Klemmer, Scott},
title = {Prototyping dynamics: sharing multiple designs improves exploration, group rapport, and results},
year = {2011},
isbn = {9781450302289},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1978942.1979359},
doi = {10.1145/1978942.1979359},
abstract = {Prototypes ground group communication and facilitate decision making. However, overly investing in a single design idea can lead to fixation and impede the collaborative process. Does sharing multiple designs improve collaboration? In a study, participants created advertisements individually and then met with a partner. In the Share Multiple condition, participants designed and shared three ads. In the Share Best condition, participants designed three ads and selected one to share. In the Share One condition, participants designed and shared one ad. Sharing multiple designs improved outcome, exploration, sharing, and group rapport. These participants integrated more of their partner's ideas into their own subsequent designs, explored a more divergent set of ideas, and provided more productive critiques of their partner's designs. Furthermore, their ads were rated more highly and garnered a higher click-through rate when hosted online.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {2807–2816},
numpages = {10},
keywords = {prototyping, exploration, design teams, critique, creativity},
location = {Vancouver, BC, Canada},
series = {CHI '11}
}

@inproceedings{10.1145/302979.303145,
author = {Toyoda, Masashi and Shibayama, Etsuya},
title = {Hyper Mochi Sheet: a predictive focusing interface for navigating and editing nested networks through a multi-focus distortion-oriented view},
year = {1999},
isbn = {0201485591},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/302979.303145},
doi = {10.1145/302979.303145},
abstract = {Multi-focus distortion-oriented views are useful in viewing large information on a small screen, but still have problems in managing multiple foci during editing. The user may have to navigate information space by focusing and defocusing multiple parts to obtain multi-focus layouts that change according to various editing situations. As a result, it becomes haphazard to navigate and edit large nested networks such as hypertexts. We propose a user interface for quickly obtaining desirable layouts. The interface uses two techniques: focus size prediction and predictive focus selection. These techniques are based on a user test and experiences in applications. We also describe two example applications.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {504–511},
numpages = {8},
keywords = {navigation, multi-focus, editing, distortion-oriented view},
location = {Pittsburgh, Pennsylvania, USA},
series = {CHI '99}
}

@inproceedings{10.1145/1753326.1753358,
author = {Freire, Manuel and Plaisant, Catherine and Shneiderman, Ben and Golbeck, Jen},
title = {ManyNets: an interface for multiple network analysis and visualization},
year = {2010},
isbn = {9781605589299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753326.1753358},
doi = {10.1145/1753326.1753358},
abstract = {Traditional network analysis tools support analysts in studying a single network. ManyNets offers these analysts a powerful new approach that enables them to work on multiple networks simultaneously. Several thousand networks can be presented as rows in a tabular visualization, and then inspected, sorted and filtered according to their attributes. The networks to be displayed can be obtained by subdivision of larger networks. Examples of meaningful subdivisions used by analysts include ego networks, community extraction, and time-based slices. Cell visualizations and interactive column overviews allow analysts to assess the distribution of attributes within particular sets of networks. Details, such as traditional node-link diagrams, are available on demand. We describe a case study analyzing a social network geared towards film recommendations by means of decomposition. A small usability study provides feedback on the use of the interface on a set of tasks issued from the case study.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {213–222},
numpages = {10},
keywords = {table interface, network analysis, interaction, information visualization, graphical user interface, exploratory analysis},
location = {Atlanta, Georgia, USA},
series = {CHI '10}
}

@inproceedings{10.1145/1753846.1754045,
author = {Ogura, Kanayo and Matsumoto, Yoko and Yamauchi, Yoshiyuki and Nishimoto, Kazushi},
title = {Kairos Chat: a novel text-based chat system that has multiple streams of time},
year = {2010},
isbn = {9781605589305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1753846.1754045},
doi = {10.1145/1753846.1754045},
abstract = {In this paper we propose a novel chat system named "Kairos Chat" that has multiple streams of time whose velocities are different. A pilot study shows that users spontaneously use the different streams for different types of messages without any concrete instructions on how to use the streams.},
booktitle = {CHI '10 Extended Abstracts on Human Factors in Computing Systems},
pages = {3721–3726},
numpages = {6},
keywords = {cmc (computer-mediated communication)},
location = {Atlanta, Georgia, USA},
series = {CHI EA '10}
}

@inproceedings{10.1145/1518701.1518895,
author = {Talbot, Justin and Lee, Bongshin and Kapoor, Ashish and Tan, Desney S.},
title = {EnsembleMatrix: interactive visualization to support machine learning with multiple classifiers},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518895},
doi = {10.1145/1518701.1518895},
abstract = {Machine learning is an increasingly used computational tool within human-computer interaction research. While most researchers currently utilize an iterative approach to refining classifier models and performance, we propose that ensemble classification techniques may be a viable and even preferable alternative. In ensemble learning, algorithms combine multiple classifiers to build one that is superior to its components. In this paper, we present EnsembleMatrix, an interactive visualization system that presents a graphical view of confusion matrices to help users understand relative merits of various classifiers. EnsembleMatrix allows users to directly interact with the visualizations in order to explore and build combination models. We evaluate the efficacy of the system and the approach in a user study. Results show that users are able to quickly combine multiple classifiers operating on multiple feature sets to produce an ensemble classifier with accuracy that approaches best-reported performance classifying images in the CalTech-101 dataset.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1283–1292},
numpages = {10},
keywords = {visualization, object recognition, interactive machine learning, ensemble classifiers, caltech-101},
location = {Boston, MA, USA},
series = {CHI '09}
}

@inproceedings{10.1145/1518701.1518933,
author = {Roth, Volker and Turner, Thea},
title = {Bezel swipe: conflict-free scrolling and multiple selection on mobile touch screen devices},
year = {2009},
isbn = {9781605582467},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1518701.1518933},
doi = {10.1145/1518701.1518933},
abstract = {Zooming user interfaces are increasingly popular on mobile devices with touch screens. Swiping and pinching finger gestures anywhere on the screen manipulate the displayed portion of a page, and taps open objects within the page. This makes navigation easy but limits other manipulations of objects that would be supported naturally by the same gestures, notably cut and paste, multiple selection, and drag and drop. A popular device that suffers from this limitation is Apple's iPhone. In this paper, we present Bezel Swipe, an interaction technique that supports multiple selection, cut, copy, paste and other operations without interfering with zooming, panning, tapping and other pre-defined gestures. Participants of our user study found Bezel Swipe to be a viable alternative to direct touch selection.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1523–1526},
numpages = {4},
keywords = {zooming, zoomable, touch interaction, swipe, study, small display, multiple selection, mode change, mobile device, iphone, handheld, gesture, cut paste, crossing},
location = {Boston, MA, USA},
series = {CHI '09}
}

@inproceedings{10.1145/1520340.1520686,
author = {Lee, David and Munson, Sean A. and Congleton, Ben and Newman, Mark W. and Ackerman, Mark S. and Hofer, Erik C. and Finholt, Thomas A.},
title = {Montage: a platform for physically navigating multiple pages of web content},
year = {2009},
isbn = {9781605582474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1520340.1520686},
doi = {10.1145/1520340.1520686},
abstract = {Montage is a platform for rendering multiple pages of web content on large tiled displays (several desktop LCDs arranged in a spatially contiguous matrix). We discuss the advantages of data visualization using a newsstand metaphor, showing many content items at once and allowing users to quickly refine visual searches by walking (physically navigating) closer to specific data on the display. We have used Montage to build three applications that demonstrate the variety of applications that are possible on this platform. These applications have benefits for both everyday use and as research tools.},
booktitle = {CHI '09 Extended Abstracts on Human Factors in Computing Systems},
pages = {4477–4482},
numpages = {6},
keywords = {tiled displays, optiportal, micro/macro view, information visualization, high resolution visualization},
location = {Boston, MA, USA},
series = {CHI EA '09}
}

@inproceedings{10.1145/1056808.1056944,
author = {Hutchings, Dugald Ralph and Stasko, John},
title = {mudibo: multiple dialog boxes for multiple monitors},
year = {2005},
isbn = {1595930027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1056808.1056944},
doi = {10.1145/1056808.1056944},
abstract = {A general problem identified in recent research on multiple monitor systems is the placement of small windows such as dialog boxes and toolbars. These small windows could be placed on top of the application window or on a monitor next to the application window; different situations call for different placements. We present mudibo, a component of the window manager that alleviates this problem by initially placing a window in multiple locations simultaneously and subsequently allowing the user to easily interact with the window in a desired location. Additional important contributions of mudibo are that as a general technique it can be applied to a number of situations and windows beyond simple dialog boxes, exploits the additional screen space that multiple monitors provide to solve a specific problem with dialog box interaction, and is among the first research prototype UIs that explicitly account for multiple-monitor users.},
booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
pages = {1471–1474},
numpages = {4},
keywords = {window management, multiple monitors, dialog box},
location = {Portland, OR, USA},
series = {CHI EA '05}
}

@inproceedings{10.1145/1357054.1357177,
author = {Dearman, David and Pierce, Jeffery S.},
title = {It's on my other computer! computing with multiple devices},
year = {2008},
isbn = {9781605580111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1357054.1357177},
doi = {10.1145/1357054.1357177},
abstract = {The number of computing devices that people use is growing. To gain a better understanding of why and how people use multiple devices, we interviewed 27 people from academia and industry. From these interviews we distill four primary findings. First, associating a user's activities with a particular device is problematic for multiple device users because many activities span multiple devices. Second, device use varies by user and circumstance; users assign different roles to devices both by choice and by constraint. Third, users in industry want to separate work and personal activities across work and personal devices, but they have difficulty doing so in practice Finally, users employ a variety of techniques for accessing information across devices, but there is room for improvement: participants reported managing information across their devices as the most challenging aspect of using multiple devices. We suggest opportunities to improve the user experience by focusing on the user rather than the applications and devices; making devices aware of their roles; and providing lighter-weight methods for transferring information, including synchronization services that engender more trust from users.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {767–776},
numpages = {10},
keywords = {user study, personal information management, personal computing, multiple devices, cross device interaction},
location = {Florence, Italy},
series = {CHI '08}
}

@inproceedings{10.1145/1357054.1357234,
author = {M\"{u}ller-Tomfelde, Christian and Schremmer, Claudia},
title = {Touchers and mousers: commonalities and differences in co-located collaboration with multiple input devices},
year = {2008},
isbn = {9781605580111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1357054.1357234},
doi = {10.1145/1357054.1357234},
abstract = {We present new findings on commonalities and differences between touch and mouse input for co-located interaction between teams of two people who know each other. Twenty-two participants were instructed to work as co-located pairs on three sets of two concurrent digital jigsaw puzzles, displayed on a horizontal tabletop that allows for multiple concurrent input devices. They were advised to use their preference for, or any combination of, direct (touch) and indirect (mouse) input device to achieve the goal. We increased the task?s difficulty: In the second and third puzzle task, participants had to discover that pieces were mixed up between the two puzzle stacks. We used this 'hidden task' to trigger spontaneous transitions from individual to collaborative work. Based on a qualitative analysis of individual interaction trajectories of direct and indirect input devices, we discuss patterns of collaboration. This furthers scientific understanding of co-located collaboration with multiple input devices.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1149–1152},
numpages = {4},
keywords = {trajectories, tabletop, multiple input devices, human factors, direct and indirect input devices, co-located collaboration},
location = {Florence, Italy},
series = {CHI '08}
}

@inproceedings{10.1145/1357054.1357201,
author = {Kobayashi, Masatomo and Igarashi, Takeo},
title = {Ninja cursors: using multiple cursors to assist target acquisition on large screens},
year = {2008},
isbn = {9781605580111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1357054.1357201},
doi = {10.1145/1357054.1357201},
abstract = {We propose the "ninja cursor" to improve the performance of target acquisition, particularly on large screens. This technique uses multiple distributed cursors to reduce the average distance to targets. Each cursor moves synchronously following mouse movement. We present the design and implementation of the proposed technique, including a method to resolve the ambiguity that results when multiple cursors indicate different targets simultaneously. We also conducted an experiment to assess the performance of the ninja cursor. The results indicate that it can generally reduce movement time. However, the performance is greatly affected by the number of cursors and target density. Based on these results, we discuss how our technique can be put into practical use. In addition to presenting a novel method to improve pointing performance, our study is the first to explore a variable number of cursors for performing pointing tasks.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {949–958},
numpages = {10},
keywords = {pointing, multiple cursors, large screens, Fitts' law},
location = {Florence, Italy},
series = {CHI '08}
}

@inproceedings{10.1145/169059.169250,
author = {Hill, Becky and Long, John and Smith, Walter and Whitefield, Andy},
title = {Planning for multiple task work: an analysis of a medical reception worksystem},
year = {1993},
isbn = {0897915755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/169059.169250},
doi = {10.1145/169059.169250},
abstract = {This paper presents an investigation of interactive worksystem planning in the multiple task work domain of medical reception. In an observational study of a medical reception worksystem, three different types of plan were identified: the task plan, the procedure plan and the activity plan. These three types of plan were required for effective working in the domain of medical reception, because of the many similar concurrent tasks, the frequency of behaviour switching between tasks, the frequency of behaviour switching between tasks and the need for consistency within the worksystem. It is proposed, therefore, that to design effective interactive human-computer worksystems for the domain of medical reception (and possibly for other work domains of a similar nature), the designer must specify the three different types of plan and the relationships between them. The three types of plan in medical reception are discussed in the context of design issues such as the allocation of planning structures.},
booktitle = {Proceedings of the INTERACT '93 and CHI '93 Conference on Human Factors in Computing Systems},
pages = {314–320},
numpages = {7},
keywords = {planning and control, multiple tasks, medical reception},
location = {Amsterdam, The Netherlands},
series = {CHI '93}
}

@inproceedings{10.1145/1357054.1357200,
author = {Biehl, Jacob T. and Baker, William T. and Bailey, Brian P. and Tan, Desney S. and Inkpen, Kori M. and Czerwinski, Mary},
title = {Impromptu: a new interaction framework for supporting collaboration in multiple display environments and its field evaluation for co-located software development},
year = {2008},
isbn = {9781605580111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1357054.1357200},
doi = {10.1145/1357054.1357200},
abstract = {We present a new interaction framework for collaborating in multiple display environments (MDEs) and report results from a field study investigating its use in an authentic work setting. Our interaction framework, IMPROMPTU, allows users to share task information across displays via off-the-shelf applications, to jointly interact with information for focused problem solving and to place information on shared displays for discussion and reflection. Our framework also includes a lightweight interface for performing these and related actions. A three week field study of our framework was conducted in the domain of face-to-face group software development. Results show that teams utilized almost every feature of the framework in support of a wide range of development-related activities. The framework was used most to facilitate opportunistic collaboration involving task information. Teams reported wanting to continue using the framework as they found value in it overall.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {939–948},
numpages = {10},
keywords = {multiple display environments, group work, group software development, field study},
location = {Florence, Italy},
series = {CHI '08}
}

@inproceedings{10.1145/1240624.1240758,
author = {Moncur, Wendy and Lepl\^{a}tre, Gr\'{e}gory},
title = {Pictures at the ATM: exploring the usability of multiple graphical passwords},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240758},
doi = {10.1145/1240624.1240758},
abstract = {Users gain access to cash, confidential information and services at Automated Teller Machines (ATMs) via an authentication process involving a Personal Identification Number (PIN). These users frequently have many different PINs, and fail to remember them without recourse to insecure behaviours. This is not a failing of users. It is a usability failing in the ATM authentication mechanism. This paper describes research executed to evaluate whether users find multiple graphical passwords more memorable than multiple PINs. The research also investigates the success of two memory augmentation strategies in increasing memorability of graphical passwords. The results demonstrate that multiple graphical passwords are substantially more effective than multiple PIN numbers. Memorability is further improved by the use of mnemonics to aid their recall.This study will be of interest to HCI practitioners and information security researchers exploring approaches to usable security.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {887–894},
numpages = {8},
keywords = {user authentication, usable security, graphical passwords, authentication mechanisms, ATMs},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240866.1241013,
author = {Gross, Benjamin M. and Churchill, Elizabeth F.},
title = {Addressing constraints: multiple usernames task spillage and notions of identity},
year = {2007},
isbn = {9781595936424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240866.1241013},
doi = {10.1145/1240866.1241013},
abstract = {In this work in progress report, we present preliminary results from an interview study on people's use of email addresses and instant messenger usernames. Based on these interview findings, we speculate that many people use multiple identifiers reactively and prosaically, rather than simply proactively and strategically. This has implications for understanding the scope of previous studies; for developing cross-platform methodologies for analysis of people's practices; for understanding identifier selection; and for design of communication tools and protocols. We believe that a focus on "identity", which we characterize to be a set of strategic and coherent practices for self-presentation/protection, has led to an under-representation of reactive and prosaic practices of identifier selection that can result from organizational policy, technological implementations, and social and task information flow management.},
booktitle = {CHI '07 Extended Abstracts on Human Factors in Computing Systems},
pages = {2393–2398},
numpages = {6},
keywords = {usernames, task, interview study, instant messaging, identity, identifier, email, collaboration},
location = {San Jose, CA, USA},
series = {CHI EA '07}
}

@inproceedings{10.1145/1240624.1240795,
author = {Oulasvirta, Antti and Sumari, Lauri},
title = {Mobile kits and laptop trays: managing multiple devices in mobile information work},
year = {2007},
isbn = {9781595935939},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240624.1240795},
doi = {10.1145/1240624.1240795},
abstract = {A study at a large IT company shows that mobile information workers frequently migrate work across devices (here: smartphones, desktop PCs, laptops). While having multiple devices provides new opportunities to work in the face of changing resource deprivations, the management of devices is often problematic. The most salient problems are posed by 1) the physical effort demanded by various management tasks, 2) anticipating what data or functionality will be needed, and 3) aligning these efforts with work, mobility, and social situations. Workers' strategies of coping with these problems center on two interwoven activities: the physical handling of devices and cross-device synchronization. These aim at balancing risk and effort in immediate and subsequent use. Workers also exhibit subtle ways to handle devices in situ, appropriating their physical and operational properties. The design implications are discussed.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {1127–1136},
numpages = {10},
keywords = {user strategies, synchronization, personal information management, multiple devices, mobile information work},
location = {San Jose, California, USA},
series = {CHI '07}
}

@inproceedings{10.1145/1240866.1240918,
author = {Yehuda, Hanna and McGinn, Jennifer},
title = {Coming to terms: comparing and combining the results of multiple evaluators performing heuristic evaluation},
year = {2007},
isbn = {9781595936424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1240866.1240918},
doi = {10.1145/1240866.1240918},
abstract = {In this paper we describe a new way to perform heuristic evaluations, which allows multiple evaluators to easily compare and combine the results of their reviews. This method was developed to provide a single, reliable, result to the client, but it also allowed us to easily negotiate differences in our findings, and to prioritize usability problems identified by the evaluation. An unexpected side effect is that, by using this evaluation method, the practitioner can measure and predict the effect of usability improvements.},
booktitle = {CHI '07 Extended Abstracts on Human Factors in Computing Systems},
pages = {1899–1904},
numpages = {6},
keywords = {usability inspection, usability evaluation, usability, severity, rating scale, heuristic evaluation, evaluator effect, competitive analysis},
location = {San Jose, CA, USA},
series = {CHI EA '07}
}

@inproceedings{10.1145/1124772.1124801,
author = {Hinckley, Ken and Guimbretiere, Francois and Baudisch, Patrick and Sarin, Raman and Agrawala, Maneesh and Cutrell, Ed},
title = {The springboard: multiple modes in one spring-loaded control},
year = {2006},
isbn = {1595933727},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1124772.1124801},
doi = {10.1145/1124772.1124801},
abstract = {Modes allow a few inputs to invoke many operations, yet if a user misclassifies or forgets the state of a system, modes can result in errors. Spring-loaded modes (quasimodes) maintain a mode while the user holds a control such as a button or key. The Springboard is an interaction technique for tablet computers that extends quasimodes to encompass multiple tool modes in a single spring-loaded control. The Springboard allows the user to continue holding down a nonpreferred-hand command button after selecting a tool from a menu as a way to repeatedly apply the same tool. We find the Springboard improves performance for both a local marking menu and for a non-local marking menu ("lagoon") at the lower left corner of the screen. Despite the round-trip costs incurred to move the pen to a tool lagoon, a keystroke-level analysis of the true cost of each technique reveals the local marking menu is not significantly faster.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {181–190},
numpages = {10},
keywords = {tablet, subtraction methodology, pen, modes, marking menus, keystroke-level model, command selection},
location = {Montr\'{e}al, Qu\'{e}bec, Canada},
series = {CHI '06}
}

@inproceedings{10.1145/634067.634113,
author = {Handel, Mark},
title = {Presence awareness: multiple sources, multiple roles},
year = {2001},
isbn = {1581133405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/634067.634113},
doi = {10.1145/634067.634113},
abstract = {Intelligent, networked devices are increasingly common, and most of these devices are capable of reporting presence information about users or sets of users. One serious limitation is that most existing presence awareness systems are unable handle multiple presence sources at once, nor are they able to handle the situation where a user is also enacting multiple roles. This work looks at some of the possible problems with multiple sources, such as when a single device could report about multiple people, or devices have conflicting data.},
booktitle = {CHI '01 Extended Abstracts on Human Factors in Computing Systems},
pages = {71–72},
numpages = {2},
keywords = {wireless, presence awareness, personas, instant messaging, cell phones},
location = {Seattle, Washington},
series = {CHI EA '01}
}

@inproceedings{10.1145/1056808.1057019,
author = {Scupelli, Peter and Kiesler, Sara and Fussell, Susan R. and Chen, Congrui},
title = {Project view IM: a tool for juggling multiple projects and teams},
year = {2005},
isbn = {1595930027},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1056808.1057019},
doi = {10.1145/1056808.1057019},
abstract = {Previous research suggests working on multiple projects may lead to stress and misallocation of attention. A modest redesign of Instant Messenger (IM) could help team members juggle multiple projects and teams. This paper describes the implementation of this redesign--an IM plug-in called Project View IM (PVIM). PVIM uses automatic project status logging to show active project-related files and team members. In a preliminary evaluation experiment, participants working collaboratively with different partners on two projects found PVIM and IM to be equally usable and informative but PVIM participants reported less workload stress. We discuss future work to iterate the design and measure allocation of attention and task performance.},
booktitle = {CHI '05 Extended Abstracts on Human Factors in Computing Systems},
pages = {1773–1776},
numpages = {4},
keywords = {workload, multitasking, instant messenger (IM), distributed work, coordination, computer mediated communication, awareness, attention, CSCW},
location = {Portland, OR, USA},
series = {CHI EA '05}
}

@inproceedings{10.1145/985692.985722,
author = {Olsen, Dan R. and Wood, Stephen Bart},
title = {Fan-out: measuring human control of multiple robots},
year = {2004},
isbn = {1581137028},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985692.985722},
doi = {10.1145/985692.985722},
abstract = {A goal of human-robot interaction is to allow one user to operate multiple robots simultaneously. In such a scenario the robots provide leverage to the user's attention. The number of such robots that can be operated is called the fan-out of a human-robot team. Robots that have high neglect tolerance and lower interaction time will achieve higher fan-out. We define an equation that relates fan-out to a robot's activity time and its interaction time. We describe how to measure activity time and fan-out. We then use the fan-out equation to compute interaction effort. We can use this interaction effort as a measure of the effectiveness of a human-robot interaction design. We describe experiments that validate the fan-out equation and its use as a metric for improving human-robot interaction.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {231–238},
numpages = {8},
keywords = {multiple robots, human-robot interaction, fan-out},
location = {Vienna, Austria},
series = {CHI '04}
}

@inproceedings{10.1145/985921.986105,
author = {Mackinlay, Jock D. and Heer, Jeffrey},
title = {Wideband displays: mitigating multiple monitor seams},
year = {2004},
isbn = {1581137036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/985921.986105},
doi = {10.1145/985921.986105},
abstract = {Wideband displays fill our field of view, creating new opportunities to develop effective visual interfaces. Although multiple monitors are becoming an affordable way to create wideband displays, the resulting seams create gaps in words and divide diagonal lines into nonaligned segments. We present several novel user interface techniques for creating seam-aware applications, showing that vendors need not wait for affordable seamless displays to exploit the potential of wideband displays.},
booktitle = {CHI '04 Extended Abstracts on Human Factors in Computing Systems},
pages = {1521–1524},
numpages = {4},
keywords = {wideband displays, seam-aware interfaces, multiple monitors},
location = {Vienna, Austria},
series = {CHI EA '04}
}

@inproceedings{10.1145/765891.766125,
author = {Wild, Peter J. and Johnson, Peter and Johnson, Hilary},
title = {An hour in the life: towards requirements for modelling multiple task work},
year = {2003},
isbn = {1581136374},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/765891.766125},
doi = {10.1145/765891.766125},
abstract = {It is accepted that changes in technology, work practices and the general socio-economic environment affect the way we plan and perform tasks. Support, opportunity and pressure for people to 'multitask' has increased. We cannot assume that because an IT is designed well for a single-user single-task perspective, that it will effectively support multitasking. Some work has been undertaken into understanding these phenomena in a HCI context, but with little permeation into mainstream HCI methods. This paper provides an interim report into work into multiple task phenomena within the Task Knowledge Structures task analysis approach.},
booktitle = {CHI '03 Extended Abstracts on Human Factors in Computing Systems},
pages = {1016–1017},
numpages = {2},
keywords = {task knowledge structures, multiple task work, modelling},
location = {Ft. Lauderdale, Florida, USA},
series = {CHI EA '03}
}

@inproceedings{10.1145/503376.503452,
author = {Robertson, George and Cameron, Kim and Czerwinski, Mary and Robbins, Daniel},
title = {Polyarchy visualization: visualizing multiple intersecting hierarchies},
year = {2002},
isbn = {1581134533},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/503376.503452},
doi = {10.1145/503376.503452},
abstract = {We describe a new information structure composed of multiple intersecting hierarchies, which we call Polyarchies. Visualizing polyarchies enables use of novel views for discovery of relationships which are very difficult using existing hierarchy visualization tools. This paper will describe the visualization design and system architecture challenges as well as our current solutions. A Mid-Tier Cache architecture is used as a "polyarchy server" which supports a novel web-based polyarchy visualization technique, called Visual Pivot. A series of five user studies guided iterative design of Visual Pivot},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {423–430},
numpages = {8},
keywords = {user studies, query language, polyarchy, metadirectory, information visualization, hierarchy, animation, 3D},
location = {Minneapolis, Minnesota, USA},
series = {CHI '02}
}

@inproceedings{10.1145/365024.365312,
author = {Grudin, Jonathan},
title = {Partitioning digital worlds: focal and peripheral awareness in multiple monitor use},
year = {2001},
isbn = {1581133278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/365024.365312},
doi = {10.1145/365024.365312},
abstract = {Software today does not help us partition our digital worlds effectively. We must organize them ourselves. This field study of users of multiple monitors examines how people with a lot of display space arrange information. Second monitors are generally used for secondary activities related to principal tasks, for peripheral awareness of information that is not the main focus, and for easy access to resources. A second monitor improves efficiency in ways that are difficult to measure yet can have substantial subjective benefit. The study concludes with illustrations of shortcomings of today's systems and applications: the way we work could be improved at relatively low cost.},
booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing Systems},
pages = {458–465},
numpages = {8},
keywords = {multiple monitors, displays, awareness},
location = {Seattle, Washington, USA},
series = {CHI '01}
}

@inproceedings{10.1145/3706599.3706665,
author = {Gupta, Kunal and Takaki, Ken and Tsutsui, Ayaka and Teramoto, Kentaro and Ryskeldiev, Bektur},
title = {AccessibleShip: Exploring Packaging and Shipping Barriers for Visually Impaired Users in C2C E-Commerce},
year = {2025},
isbn = {9798400713958},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706599.3706665},
doi = {10.1145/3706599.3706665},
abstract = {People with Visual Impairment (PVI) face numerous challenges when engaging in Customer-to-Customer (C2C) e-commerce, particularly in tasks like listing, packaging, shipping, and post-sale interactions. This case study investigates the accessibility barriers that prevent visually impaired users from independently managing the selling process on C2C platforms. Through semi-structured interviews with eight participants with low vision, we identified challenges, such as reliance on assistance, inaccessible platform interfaces, and difficulties in offline tasks. The study highlights the need for AI-powered assistive tools, accessible design improvements, and integrated post-sale management systems. Our findings contribute actionable insights for inclusive design practices, aiming to foster independence and satisfaction for visually impaired users in digital marketplaces.},
booktitle = {Proceedings of the Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {656},
numpages = {8},
keywords = {accessibility, e-commerce, packaging, online shopping, user studies},
location = {
},
series = {CHI EA '25}
}

@inproceedings{10.1145/3491102.3502063,
author = {Lei, Wentao and Fan, Mingming and Thang, Juliann},
title = {“I Shake The Package To Check If It’s Mine”: A Study of Package Fetching Practices and Challenges of Blind and Low Vision People in China},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502063},
doi = {10.1145/3491102.3502063},
abstract = {With about 230 million packages delivered per day in 2020, fetching packages has become a routine for many city dwellers in China. When fetching packages, people usually need to go to collection sites of their apartment complexes or a KuaiDiGui, an increasingly popular type of self-service package pickup machine. However, little is known whether such processes are accessible to blind and low vision (BLV) city dwellers. We interviewed BLV people (N=20) living in a large metropolitan area in China to understand their practices and challenges of fetching packages. Our findings show that participants encountered difficulties in finding the collection site and localizing and recognizing their packages. When fetching packages from KuaiDiGuis, they had difficulty in identifying the correct KuaiDiGui, interacting with its touch screen, navigating the complex on-screen workflow, and opening the target compartment. We discuss design considerations to make the package fetching process more accessible to the BLV community.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {268},
numpages = {15},
keywords = {Accessibility, Blind and low vision, China, Interview, KuaiDiGui, Package delivery, People with vision impairments, Qualitative study},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3170427.3188563,
author = {Borowski, Marcel and R\"{a}dle, Roman and Klokmose, Clemens N.},
title = {Codestrate Packages: An Alternative to "One-Size-Fits-All" Software},
year = {2018},
isbn = {9781450356213},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3170427.3188563},
doi = {10.1145/3170427.3188563},
abstract = {We present Codestrate Packages, a package-based system to create extensible software within Codestrates. Codestrate Packages turns content creation from an application-centric model into a document-centric model. Codestrate Packages no longer restrict users to the feature set of the application. Instead packages allow users to add new features to their documents while already working on them. They can match the features to their current task at hand. Supporting the reprogrammable nature of Codestrates, new features can also be implemented by users themselves and shared with other people without having to leave the document. We illustrate the application of Codestrate Packages in an example scenario and present its technical concepts. We plan to conduct multiple user studies to investigate the benefits and barriers of Codestrate Packages' document-centric approach.},
booktitle = {Extended Abstracts of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–6},
numpages = {6},
keywords = {document-centric, extensible systems, package management, reprogrammable systems},
location = {Montreal QC, Canada},
series = {CHI EA '18}
}

@inproceedings{10.1145/2468356.2468776,
author = {Wilfinger, David and Meschtscherjakov, Alexander and Perterer, Nicole and Murer, Martin and Laminger, Arno and Tscheligi, Manfred},
title = {Automotive HMI test package: an exploitable approach to study in-car HMIs},
year = {2013},
isbn = {9781450319522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2468356.2468776},
doi = {10.1145/2468356.2468776},
abstract = {This case study describes the development of a method package for evaluating in-car HMIs holistically. The goal is to provide a toolbox that is easy to replicate and allows evaluators to identify the effects of the system usage on the drivers' state. Additionally it aims at finding interface flaws that cause distraction and negative experiences. We applied the toolbox in two example studies, which informed the further application of the HMI study approach. We learned that the combination of established expert and end user methods with a real test track leads to useful results that are easy to communicate to both scientific and public audiences.},
booktitle = {CHI '13 Extended Abstracts on Human Factors in Computing Systems},
pages = {2377–2380},
numpages = {4},
keywords = {evaluation., distraction, case study, automotive hmi},
location = {Paris, France},
series = {CHI EA '13}
}

@inproceedings{10.1145/2702613.2726964,
author = {Kim, Yongsung},
title = {Libero: On-the-go Crowdsourcing for Package Delivery},
year = {2015},
isbn = {9781450331463},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2702613.2726964},
doi = {10.1145/2702613.2726964},
abstract = {Throughout the world, millions of people walk, bike, and run the same routes at the same time, every day. This patterned, collective effort represents a potentially valuable yet underutilized resource for sensing, transporting goods, or completing small tasks that advance individual and societal goals. In this paper, we introduce a system called Libero, which utilizes people's existing routine for package delivery by incorporating just-in-time notifications in hopes of reducing task distance to an extreme (50 meters) and having a community support itself in doing simple tasks for one another. The results of preliminary studies show that just-in-time notifications helped promoting delivery, but other factors, such as reciprocity, community building, and social obligation were also important drivers for promoting participation.},
booktitle = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems},
pages = {121–126},
numpages = {6},
keywords = {physical crowdsourcing, on-the-go crowdsourcing, mobile crowdsourcing, crowdsourcing},
location = {Seoul, Republic of Korea},
series = {CHI EA '15}
}

@inproceedings{10.1145/800275.810922,
author = {Greenberg, Edward A. and Ivey, Wm. Max and Lewis, Bruce R.},
title = {Comparison of some available packages for use in research data management},
year = {1981},
isbn = {0897910567},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/800275.810922},
doi = {10.1145/800275.810922},
abstract = {Data management features of SIR, SAS, and SPSS were applied to a sample hierarchical data base. For each package, the areas investigated included the logical definition of the data base, data entry, data retrieval, data integrity, security, reporting, and updating.},
booktitle = {Proceedings of the Joint Conference on Easier and More Productive Use of Computer Systems. (Part - I): Information Processing in the Social Sciences and Humanities - Volume 1981},
pages = {1–8},
numpages = {8},
keywords = {SPSS, SIR, SAS, Information retrieval, Data retrieval, Data management, Data base},
location = {Ann Arbor, MI},
series = {CHI '81}
}

